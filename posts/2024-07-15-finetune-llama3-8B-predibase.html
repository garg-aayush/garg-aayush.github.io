<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-07-15">
<meta name="description" content="Blog on fine-tuning a Llama-3-8B model on the Predibase platform for structured functional representation extraction, and compare its performance with GPT-4 and Claude 3.5 Sonnet.">

<title>Part III: Fine-tuning Llama-3-8B for Structured Functional Representation Extraction ‚Äì Aayush Garg</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../static/img/aayush_cropped.jpg" rel="icon" type="image/jpeg">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-4d9ea9f5848f487b1d5c615e269b8734.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
          <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog/"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../publications.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/garg-aayush"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/aayush-garg-8b26a734"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Aayush_ander"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
</div>
            <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#task-and-dataset" id="toc-task-and-dataset" class="nav-link active" data-scroll-target="#task-and-dataset">Task and Dataset</a></li>
  <li><a href="#upload-the-dataset-to-predibase" id="toc-upload-the-dataset-to-predibase" class="nav-link" data-scroll-target="#upload-the-dataset-to-predibase">Upload the dataset to Predibase</a></li>
  <li><a href="#setup-and-finetune" id="toc-setup-and-finetune" class="nav-link" data-scroll-target="#setup-and-finetune">Setup and Finetune</a></li>
  <li><a href="#evaluate-the-fine-tuned-model" id="toc-evaluate-the-fine-tuned-model" class="nav-link" data-scroll-target="#evaluate-the-fine-tuned-model">Evaluate the Fine-tuned Model</a>
  <ul class="collapse">
  <li><a href="#generate-the-responses-for-validation-dataset" id="toc-generate-the-responses-for-validation-dataset" class="nav-link" data-scroll-target="#generate-the-responses-for-validation-dataset">Generate the responses for validation dataset</a></li>
  </ul></li>
  <li><a href="#improved-performance-with-updated-prompt-template" id="toc-improved-performance-with-updated-prompt-template" class="nav-link" data-scroll-target="#improved-performance-with-updated-prompt-template">Improved Performance with Updated Prompt Template</a></li>
  <li><a href="#conclusions.." id="toc-conclusions.." class="nav-link" data-scroll-target="#conclusions..">Conclusions..</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next steps‚Ä¶</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Part III: Fine-tuning Llama-3-8B for Structured Functional Representation Extraction</h1>
</div>

<div>
  <div class="description">
    Blog on fine-tuning a Llama-3-8B model on the Predibase platform for structured functional representation extraction, and compare its performance with GPT-4 and Claude 3.5 Sonnet.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 15, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Last week, I published the <a href="https://aayushgarg.dev/2024-07-09-compare-models-structured-data/">second blog</a> in my LLM fine-tuning series, comparing various models performance in functional representation extraction.</p>
<p>In this third part of the series, I discuss the <strong>first steps toward fine-tuning an (open-source)-LLM for functional representation extraction</strong>. My aim is to give you all a sneak peek at the kind of performance you can expect from fine-tuning an LLM for a custom task. To streamline this step (and to satisfy my own curiosity üòä), I will use <a href="https://predibase.com/">Predibase</a>. It is a fast, cheap, and efficient open-source LLM fine-tuning and deployment platform.</p>
<blockquote class="blockquote">
<p>FYI: I have some free Predibase credits through Dan‚Äôs and Hamel‚Äôs LLM course. Therefore, it is a perfect opportunity to put those credits to good use! üò¨</p>
</blockquote>
<blockquote class="blockquote">
<p>Note: Whenever I mention ‚Äúfinetuning LLM,‚Äù I am specifically referring to LoRA (Low-Rank Adaptation) finetuning of a Large Language Model. For overview of LoRA, please read Sebastian Raschka‚Äôs blogs (<a href="https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html">LORA Blog 1</a>, <a href="https://magazine.sebastianraschka.com/p/llm-research-insights-instruction">LORA Blog 2</a>).</p>
</blockquote>
<section id="task-and-dataset" class="level2">
<h2 class="anchored" data-anchor-id="task-and-dataset">Task and Dataset</h2>
<p>Similar to my previous blogs, the custom task is to predict the structured functional representation from the given text video game opinions of the <a href="https://huggingface.co/datasets/GEM/viggo">ViGGO validation dataset</a>.</p>
<p><strong>To make this exercise interesting and challenging for future experiments, I will use a maximum of 1000 examples for fine-tuning any LLM model, instead of the full ~5K train dataset</strong>.</p>
<p>Below is an example from the randomly selected <code>1K</code> train dataset:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>Text                      : I remember you saying that you loved The Room. Do you tend to enjoy PC games <span class="im">from</span> <span class="dv">2012</span>?</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>functional_representation : verify_attribute(name[The Room], release_year[<span class="dv">2012</span>], rating[excellent], platforms[PC])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>As shown in the graph below, the selected <code>1K</code> dataset is a fairly representative sample of the full ViGGO train dataset.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../static/img/blog-2024-07-15/viggo_function_name_distribution_1K.png" class="img-fluid figure-img"></p>
<figcaption>Understanding Data Distribution</figcaption>
</figure>
</div>
</section>
<section id="upload-the-dataset-to-predibase" class="level2">
<h2 class="anchored" data-anchor-id="upload-the-dataset-to-predibase">Upload the dataset to Predibase</h2>
<p>Predibase requires you to upload the instruction fine-tuning dataset in particular format. This is from <a href="https://docs.predibase.com/user-guide/fine-tuning/prepare-data#how-to-structure-your-dataset">Predibase docs</a>:</p>
<blockquote class="blockquote">
<p>For instruction fine-tuning, your dataset must contain two columns named prompt and completion: - prompt: Your input prompt. It serves as the starting point or the guiding information for the model. - completion: The expected response that corresponds to the input provided in the ‚Äúprompt‚Äù column. - split (optional): Should be either train or evaluation. To learn more, check out this section.</p>
</blockquote>
<p><strong>Make sure to add the prompt template to the examples and convert them to the correct format.</strong> For this exercise, I use the following prompt template:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>prompt_template <span class="op">=</span> <span class="st">"""Given a target sentence convert it structured functional representation.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="st">### Target sentence: </span><span class="sc">{text}</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="st">### Output Functional representation:</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>You can connect your dataset to Predibase via the UI or Python SDK. Here, I will upload the dataset using SDK.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Predibase client</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>pb <span class="op">=</span> Predibase(api_token<span class="op">=</span>os.environ[<span class="st">"PREDIBASE_API_TOKEN"</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload the dataset</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> pb.datasets.from_file(<span class="st">"viggo_train_val_dataset_1K.csv"</span>, </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>                                name<span class="op">=</span><span class="st">"viggo_train_val_dataset_1K"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Once uploade, you can check the uploaded dataset on the Predibase UI. <img src="../static/img/blog-2024-07-15/predibase_ui_dataset.png" class="img-fluid" alt="Dataset"> <img src="../static/img/blog-2024-07-15/predibase_ui_dataset2.png" class="img-fluid" alt="Dataset"></p>
<p>For detailed steps on uploading the dataset to Predibase, please refer to the companion <a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Finetune_llama-3-8b_Predibase.ipynb">blog notebook</a>.</p>
</section>
<section id="setup-and-finetune" class="level2">
<h2 class="anchored" data-anchor-id="setup-and-finetune">Setup and Finetune</h2>
<p>Once you have uploaded the dataset, running the fine-tuning process is refreshingly simple. For this example, I fine-tune the base <code>llama-3-8b</code> model with the following parameters: <code>epochs=3</code>, <code>rank=16</code>, and <code>learning_rate=2e-4</code>.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an adapter repository</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>repo <span class="op">=</span> pb.repos.create(name<span class="op">=</span><span class="st">"viggo-finetune-1K"</span>, </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                description<span class="op">=</span><span class="st">"Llama-3-8b adapter repository for viggo 1K examples"</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and run the fine-tuning job</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>adapter <span class="op">=</span> pb.adapters.create(</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>   config<span class="op">=</span>FinetuningConfig(</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>       base_model<span class="op">=</span><span class="st">"llama-3-8b"</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>       epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>       rank<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>       learning_rate<span class="op">=</span><span class="fl">0.0002</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>   ),</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>   dataset<span class="op">=</span>dataset,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>   repo<span class="op">=</span>repo,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>   description<span class="op">=</span><span class="st">"baseline-llama-3-8b"</span>,</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>That‚Äôs all you need to do to submit a job! Once completed, it will be available on the Predibase platform.</p>
<p><img src="../static/img/blog-2024-07-15/predibase_ui_train1.png" class="img-fluid" alt="train-1"> <img src="../static/img/blog-2024-07-15/predibase_ui_train2.png" class="img-fluid" alt="train-2"></p>
<p>You can always tweak multiple hyperparameters (see <a href="https://docs.predibase.com/sdk-guide/SDKv2/ConfigClasses/FineTuningConfig">Finetuning Config</a>) and run the fine-tune job again. All your fine-tune jobs will be available on the Predibase platform.</p>
</section>
<section id="evaluate-the-fine-tuned-model" class="level2">
<h2 class="anchored" data-anchor-id="evaluate-the-fine-tuned-model">Evaluate the Fine-tuned Model</h2>
<p>Predibase provides both popular <code>Serverless endpoints</code> and <code>Dedicated deployments</code> options for opens-source LLMs and their fine-tuned LORA checkpoints. I will create serverless endpoint for this case.</p>
<blockquote class="blockquote">
<p>Note, atleast for now, <a href="https://docs.predibase.com/user-guide/inference/serverless_endpoints">serverless deployments</a> are available for free.</p>
</blockquote>
<section id="generate-the-responses-for-validation-dataset" class="level3">
<h3 class="anchored" data-anchor-id="generate-the-responses-for-validation-dataset">Generate the responses for validation dataset</h3>
<p>Similar to my previous blogs, I will evaluate the finetuned model on ViGGO <code>validation</code> dataset and calculate custom <a href="https://aayushgarg.dev/2024-07-09-compare-models-structured-data/">performance metrics</a> metrics for a better understanding of finetuned model performance.</p>
<p>First, I generate the responses for the validation dataset:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Predibase deployment client</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>lorax_client <span class="op">=</span> pb.deployments.client(<span class="st">"llama-3-8b"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the validation dataset</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>viggo_dataset <span class="op">=</span> load_dataset(<span class="st">"GEM/viggo"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> viggo_dataset[<span class="st">'validation'</span>]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># finetuned adapter id</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>adapter_id <span class="op">=</span> <span class="st">"viggo-finetune-1K/2"</span> </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>responses_dict <span class="op">=</span> {}</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(val_dataset)):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">%</span> <span class="dv">50</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(<span class="ss">f"Processing </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(val_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> lorax_client.generate(prompt_template.<span class="bu">format</span>(text<span class="op">=</span>val_dataset[<span class="st">"target"</span>][idx]), adapter_id<span class="op">=</span><span class="st">"viggo-finetune-1K/2"</span>, max_new_tokens<span class="op">=</span><span class="dv">150</span>).generated_text</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    ground_truth <span class="op">=</span> val_dataset[<span class="st">"meaning_representation"</span>][idx]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> val_dataset[<span class="st">"target"</span>][idx]</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    responses_dict[idx] <span class="op">=</span> {<span class="st">"output"</span>: output, <span class="st">"ground_truth"</span>: ground_truth, <span class="st">"text"</span>: text}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Note: Remember to replace ‚Äúviggo-finetune-1K/2‚Äù with the correct adapter ID. You can find the adapter ID in the Predibase dashboard.</strong></p>
<p>Now, I can generate the evaluation scores using custom evaluation metrics and compare them with previously calculated GPT-4 and Claude 3.5 Sonnet scores:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../static/img/blog-2024-07-15/finetuned_llama-3-8B_baseline.png" class="img-fluid figure-img"></p>
<figcaption>plot-finetuned-model</figcaption>
</figure>
</div>
<p>The initial finetuning of LLaMA-3-8B using 1,000 random examples from the ViGGO dataset, while not surpassing GPT-4 and Claude 3.5 Sonnet, shows promising results and outperforms several models from our previous blog. Notably, the exact_match score is even better than that of the two best-performing models.</p>
</section>
</section>
<section id="improved-performance-with-updated-prompt-template" class="level2">
<h2 class="anchored" data-anchor-id="improved-performance-with-updated-prompt-template">Improved Performance with Updated Prompt Template</h2>
<p>A simple yet effective way to enhance the model‚Äôs performance is by refining the prompt template. By providing clearer instructions that convey the structure of the functional representation, we can guide the model to produce more accurate outputs.</p>
<p>I updated the prompt template as follows:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>prompt_template <span class="op">=</span> <span class="st">"""Given a target sentence construct the underlying meaningful functional representation of the input sentence as a single function with attributes and attribute values.</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="st">### Target sentence: </span><span class="sc">{text}</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="st">### Output Functional representation:</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>After uploading this new dataset, finetuning the model, and evaluating it with the new adapter <code>viggo-finetune-1K/3</code>, there is significantly improved evaluation metrics. Notably, the model now surpasses GPT-4o‚Äôs scores for <code>exact_match</code> and <code>function_name_match</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../static/img/blog-2024-07-15/finetuned_llama-3-8B_update1.png" class="img-fluid figure-img"></p>
<figcaption>plot-finetuned-model</figcaption>
</figure>
</div>
<p><strong>This improvement highlights the importance of clear and specific instructions in prompt engineering, even when working with finetuned models.</strong></p>
</section>
<section id="conclusions.." class="level2">
<h2 class="anchored" data-anchor-id="conclusions..">Conclusions..</h2>
<ul>
<li><p>First of all, <strong>My overall experience with Predibase has been positive, particularly in terms of rapid finetuning of models</strong>. While there are some limitations such as restricted hyperparameter tuning, standardized dataset format, and inability to download adapters in the developer tier, it offers a user-friendly platform for fine-tuning (LORA) large language models. I was able to quickly upload, setut, finetune and infer the llm models.</p></li>
<li><p>I achieve out-of-the-box performance using only random <code>1K</code> examples. Although the fine-tuned llama-3-8b model doesn‚Äôt match the performance of GPT-4 and Sonnet 3.5 on all metrics. <strong>This demonstrates the potential of fine-tuning with limited data, highlighting the efficiency of the approach for task-specific model adaptation.</strong></p></li>
</ul>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps‚Ä¶</h2>
<ul>
<li>My next goal is to further enhance the model‚Äôs performance on evaluation metrics while maintaining a limit of 1,000 training examples. <em><strong><a href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment</a></strong> paper has demonstrated in the past that even 1,000 well-curated examples can lead to strong finetuning performance.</em></li>
<li>Careful curated selection of examples and hyerparameters will definitely improve the performance benchmarks on evaluation metrics.</li>
<li>In addition to it, I will deep dive into one of my favorite LLM fine-tuning tools, <a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a>.</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://aayushgarg.dev/2024-07-03-baseline-gpt4o-structured-data/">Part II blog post of series</a></li>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Analyze_Viggo_Dataset.ipynb">Notebook I: Analyze_Viggo_Dataset.ipynb</a></li>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Finetune_llama-3-8b_Predibase.ipynb">Notebook II: Finetune_llama-3-8b_Predibase.ipynb</a></li>
<li><a href="https://predibase.com/">Predibase Platform</a></li>
<li><a href="https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html">LORA blog I: Finetuning Large Language Models (LLMs)</a></li>
<li><a href="https://magazine.sebastianraschka.com/p/llm-research-insights-instruction">LORA blog II: LLM Research Insights: Instruction Tuning &amp; Training Paradigms</a></li>
<li><a href="https://llama.meta.com/llama3/">Llama 3</a></li>
<li><a href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment</a></li>
<li><a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl: A Framework for Fine-tuning LLMs</a></li>
</ul>
<hr>
<p>Thanks for reading! If you have any questions or feedback, please let me know on <a href="https://twitter.com/Aayush_ander">Twitter</a> or <a href="https://www.linkedin.com/in/aayush-garg-8b26a734/">LinkedIn</a>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/garg-aayush\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/garg-aayush">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/aayush-garg-8b26a734">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Aayush_ander">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>