<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-09-08">
<meta name="description" content="This blog summarizes building the GPT architecture by following Andrej Karpathy’s ‘Let’s Build GPT’ tutorial.">

<title>Building GPT from Scratch: Following Karpathy’s Tutorial – Aayush Garg</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../static/img/aayush_cropped.jpg" rel="icon" type="image/jpeg">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-2d3f84a5f37526cd3979248aedf2fbfb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-16JWTLXJNG"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-16JWTLXJNG', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
          <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog/"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../publications.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/garg-aayush"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/aayush-garg-8b26a734"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Aayush_ander"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
</div>
            <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#baseline-bigram-model-e0b5864" id="toc-baseline-bigram-model-e0b5864" class="nav-link active" data-scroll-target="#baseline-bigram-model-e0b5864">Baseline: Bigram Model (<code>e0b5864</code>)</a></li>
  <li><a href="#update-1-self-attention-7b0e03a" id="toc-update-1-self-attention-7b0e03a" class="nav-link" data-scroll-target="#update-1-self-attention-7b0e03a">Update 1: Self-Attention (<code>7b0e03a</code>)</a></li>
  <li><a href="#update-2-multi-head-attention-9d2a7b5" id="toc-update-2-multi-head-attention-9d2a7b5" class="nav-link" data-scroll-target="#update-2-multi-head-attention-9d2a7b5">Update 2: Multi-Head Attention (<code>9d2a7b5</code>)</a></li>
  <li><a href="#update-3-feed-forward-network-c4c46ff" id="toc-update-3-feed-forward-network-c4c46ff" class="nav-link" data-scroll-target="#update-3-feed-forward-network-c4c46ff">Update 3: Feed-Forward Network (<code>c4c46ff</code>)</a></li>
  <li><a href="#update-4-residual-connections-0239c07" id="toc-update-4-residual-connections-0239c07" class="nav-link" data-scroll-target="#update-4-residual-connections-0239c07">Update 4: Residual Connections (<code>0239c07</code>)</a></li>
  <li><a href="#update-5-6-layer-normalization-63ef5f8-4f5bef8" id="toc-update-5-6-layer-normalization-63ef5f8-4f5bef8" class="nav-link" data-scroll-target="#update-5-6-layer-normalization-63ef5f8-4f5bef8">Update 5 &amp; 6: Layer Normalization (<code>63ef5f8</code>, <code>4f5bef8</code>)</a></li>
  <li><a href="#update-7-scaling-up-d4141d7" id="toc-update-7-scaling-up-d4141d7" class="nav-link" data-scroll-target="#update-7-scaling-up-d4141d7">Update 7: Scaling Up (<code>d4141d7</code>)</a></li>
  <li><a href="#how-this-compares-to-gpt-3" id="toc-how-this-compares-to-gpt-3" class="nav-link" data-scroll-target="#how-this-compares-to-gpt-3">How This Compares to GPT-3</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Building GPT from Scratch: Following Karpathy’s Tutorial</h1>
</div>

<div>
  <div class="description">
    This blog summarizes building the GPT architecture by following Andrej Karpathy’s ‘Let’s Build GPT’ tutorial.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 8, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>The Transformer architecture has become the workhorse behind modern LLMs. GPT-2/3/4/5, Llama, Claude, Gemini: they all are built on top of the same core architecture or its variants from the 2017 “Attention Is All You Need” paper. I wanted to understand this architecture properly, so I followed Andrej Karpathy’s <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">“Let’s Build GPT from Scratch”</a> video. It’s a 2-hour walkthrough where you start from an empty file and end up with a working Transformer.</p>
<p>I followed Karpathy’s video and captured each architectural addition as a separate commit. This let me see exactly how each component pulled down the validation loss. In this walkthrough, the training data is ~1M characters of Shakespeare and the goal is to generate Shakespeare-like text.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>Component</th>
<th>Val Loss</th>
<th>Commit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Baseline</td>
<td>Bigram Model</td>
<td>~2.49</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/e0b5864"><code>e0b5864</code></a></td>
</tr>
<tr class="even">
<td>Update 1</td>
<td>Single Head Self-Attention</td>
<td>~2.4</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/7b0e03a"><code>7b0e03a</code></a></td>
</tr>
<tr class="odd">
<td>Update 2</td>
<td>Multi-Head Attention</td>
<td>~2.28</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/9d2a7b5"><code>9d2a7b5</code></a></td>
</tr>
<tr class="even">
<td>Update 3</td>
<td>Feed-Forward Network</td>
<td>~2.27</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/c4c46ff"><code>c4c46ff</code></a></td>
</tr>
<tr class="odd">
<td>Update 4</td>
<td>Residual Connections</td>
<td>~2.09</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/0239c07"><code>0239c07</code></a></td>
</tr>
<tr class="even">
<td>Update 5</td>
<td>Layer Normalization</td>
<td>~2.076</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/63ef5f8"><code>63ef5f8</code></a></td>
</tr>
<tr class="odd">
<td>Update 6</td>
<td>Pre-LayerNorm (modern)</td>
<td>~2.076</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/4f5bef8"><code>4f5bef8</code></a></td>
</tr>
<tr class="even">
<td>Update 7</td>
<td>Scaling Up + Dropout</td>
<td>~1.48</td>
<td><a href="https://github.com/garg-aayush/building-from-scratch/commit/d4141d7"><code>d4141d7</code></a></td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/garg-aayush/building-from-scratch/main/basic-gpt/images/loss_curves.png" class="img-fluid figure-img"></p>
<figcaption>Loss Curves</figcaption>
</figure>
</div>
<p>You can find all the code and notebooks in the repo: <a href="https://github.com/garg-aayush/building-from-scratch/tree/main/basic-gpt">building-from-scratch/basic-gpt</a></p>
<section id="baseline-bigram-model-e0b5864" class="level2">
<h2 class="anchored" data-anchor-id="baseline-bigram-model-e0b5864">Baseline: Bigram Model (<a href="https://github.com/garg-aayush/building-from-scratch/commit/e0b5864"><code>e0b5864</code></a>)</h2>
<p>Karpathy starts with the simplest possible language model: a bigram model. It predicts the next character based only on the current character. No context at all. The tokens aren’t talking to each other.</p>
<p>This still works somewhat because some characters naturally follow others (the letter ‘q’ is almost always followed by ‘u’). But the output is complete gibberish because the model has no way to look at what came before.</p>
<p><strong>Result</strong>: ~2.49 validation loss.</p>
</section>
<section id="update-1-self-attention-7b0e03a" class="level2">
<h2 class="anchored" data-anchor-id="update-1-self-attention-7b0e03a">Update 1: Self-Attention (<a href="https://github.com/garg-aayush/building-from-scratch/commit/7b0e03a"><code>7b0e03a</code></a>)</h2>
<p>We want tokens to communicate with each other and predictions to consider context from previous tokens, not just the current one. A token at position 5 should be able to look at tokens 1-4 and gather information from them. But at the same time, it can’t look at tokens 6, 7, 8 because those are the future we’re trying to predict.</p>
<p>Self-attention solves this. Every token is represented by 3 vectors: - <strong>Query</strong>: “What am I looking for?” - <strong>Key</strong>: “What do I contain?”<br>
- <strong>Value</strong>: “If you find me interesting, here’s what I’ll tell you.”</p>
<p>The query dot-products with all the keys. High dot product means high affinity: “I find you interesting.” The values of interesting tokens get aggregated via weighted sum.</p>
<blockquote class="blockquote">
<p><strong>Note</strong>: Attention is really a communication mechanism. You can think of it as nodes in a directed graph where every node aggregates information from nodes that point to it. In our case, token 5 can receive information from tokens 1-4 (and itself), but not from tokens 6-8. The triangular mask creates this directed structure and is what makes this a “decoder” block.</p>
</blockquote>
<p>One subtle but important point: attention has no notion of space. The tokens don’t inherently know where they are in the sequence. That’s why we add <strong>positional embeddings</strong>. Each position gets its own learned embedding that’s added to the token embedding, giving the model spatial information.</p>
<p><strong>Result</strong>: ~2.4 validation loss. Tokens can now see context.</p>
</section>
<section id="update-2-multi-head-attention-9d2a7b5" class="level2">
<h2 class="anchored" data-anchor-id="update-2-multi-head-attention-9d2a7b5">Update 2: Multi-Head Attention (<a href="https://github.com/garg-aayush/building-from-scratch/commit/9d2a7b5"><code>9d2a7b5</code></a>)</h2>
<p>Tokens have a lot to talk about. One head might look for consonants, another for vowels, another for word boundaries, another for patterns at specific positions. Having multiple independent communication channels lets the model gather diverse types of data in parallel.</p>
<blockquote class="blockquote">
<p><strong>Note</strong>: This is similar to grouped convolutions. Instead of one large convolution, you do it in groups. With 4 heads of 8 dimensions each, we get the same total dimensionality (32) but with 4 separate communication channels. Each head can specialize in different patterns.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/garg-aayush/building-from-scratch/main/basic-gpt/images/MHA.png" class="img-fluid figure-img"></p>
<figcaption>Multi-Head Attention</figcaption>
</figure>
</div>
<p><strong>Result</strong>: ~2.28 validation loss.</p>
</section>
<section id="update-3-feed-forward-network-c4c46ff" class="level2">
<h2 class="anchored" data-anchor-id="update-3-feed-forward-network-c4c46ff">Update 3: Feed-Forward Network (<a href="https://github.com/garg-aayush/building-from-scratch/commit/c4c46ff"><code>c4c46ff</code></a>)</h2>
<p>The FFN layer addresses a key problem. Until now, “the tokens looked at each other but didn’t have enough time to think about what they found.”</p>
<p>Self-attention is the <strong>communication</strong> phase. Tokens gather data from each other. But then they need to <strong>compute</strong> on that data individually. That’s what the feed-forward network does. It operates on a per-token level. All the tokens process their gathered information independently.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/garg-aayush/building-from-scratch/main/basic-gpt/images/FFN.png" class="img-fluid figure-img"></p>
<figcaption>Feed-Forward Network</figcaption>
</figure>
</div>
<p>So the Transformer block becomes: <strong>communicate</strong> (attention) → <strong>compute</strong> (feed-forward). This pattern repeats for every layer.</p>
<p><strong>Result</strong>: ~2.27 validation loss. The architecture now has both communication and computation.</p>
</section>
<section id="update-4-residual-connections-0239c07" class="level2">
<h2 class="anchored" data-anchor-id="update-4-residual-connections-0239c07">Update 4: Residual Connections (<a href="https://github.com/garg-aayush/building-from-scratch/commit/0239c07"><code>0239c07</code></a>)</h2>
<p>This is one of two optimizations that make deep networks actually trainable. Without it, stacking many layers leads to vanishing gradients and optimization difficulties.</p>
<p>Karpathy visualizes it nicely: imagine a residual pathway running from top to bottom. You can “fork off” from this pathway, do some computation, and project back via addition. The path from inputs to outputs is just a series of additions.</p>
<blockquote class="blockquote">
<p><strong>Note</strong>: Why does this help? During backpropagation, addition distributes gradients equally to both branches. The gradients “hop” through every addition node directly to the input. This creates a <strong>“gradient superhighway”</strong> from supervision to input, unimpeded. The residual blocks are initialized to contribute very little at first, then “come online” over time during optimization.</p>
</blockquote>
<p><strong>Result</strong>: ~2.09 validation loss. Now we can stack layers without vanishing gradients.</p>
</section>
<section id="update-5-6-layer-normalization-63ef5f8-4f5bef8" class="level2">
<h2 class="anchored" data-anchor-id="update-5-6-layer-normalization-63ef5f8-4f5bef8">Update 5 &amp; 6: Layer Normalization (<a href="https://github.com/garg-aayush/building-from-scratch/commit/63ef5f8"><code>63ef5f8</code></a>, <a href="https://github.com/garg-aayush/building-from-scratch/commit/4f5bef8"><code>4f5bef8</code></a>)</h2>
<p>Batch normalization normalizes columns (across examples in a batch). Layer normalization normalizes rows (across features for each example). The implementation is almost identical, you just change which dimension you normalize over.</p>
<p>Layer norm has advantages for Transformers: - No dependency on batch size (works even with batch size 1) - No running buffers to maintain - No distinction between training and test time</p>
<p>The original Transformer paper used <strong>post-layer norm</strong> (normalize after attention/FFN). Modern implementations use <strong>pre-layer norm</strong> (normalize before). Pre-layer norm creates a cleaner residual pathway since the transformation happens on normalized inputs, leading to more stable training.</p>
<p><strong>Result</strong>: ~2.076 validation loss.</p>
</section>
<section id="update-7-scaling-up-d4141d7" class="level2">
<h2 class="anchored" data-anchor-id="update-7-scaling-up-d4141d7">Update 7: Scaling Up (<a href="https://github.com/garg-aayush/building-from-scratch/commit/d4141d7"><code>d4141d7</code></a>)</h2>
<p>With all the architectural pieces in place, Karpathy scales up the architecture:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Parameter</th>
<th>Before</th>
<th>After</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Block size (context)</td>
<td>8</td>
<td>256</td>
</tr>
<tr class="even">
<td>Embedding dim</td>
<td>32</td>
<td>384</td>
</tr>
<tr class="odd">
<td>Heads</td>
<td>4</td>
<td>6</td>
</tr>
<tr class="even">
<td>Layers</td>
<td>3</td>
<td>6</td>
</tr>
<tr class="odd">
<td>Dropout</td>
<td>0</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>Dropout is added for regularization. It randomly shuts off neurons during training, effectively training an ensemble of sub-networks. At test time, everything is enabled and the sub-networks merge.</p>
<p><strong>Result</strong>: ~1.48 validation loss. The generated text now looks like Shakespeare (structure, dialogue formatting, character names) even though it’s nonsensical when you actually read it.</p>
</section>
<section id="how-this-compares-to-gpt-3" class="level2">
<h2 class="anchored" data-anchor-id="how-this-compares-to-gpt-3">How This Compares to GPT-3</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>My Model</th>
<th>GPT-3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Parameters</td>
<td>~10M</td>
<td>175B</td>
</tr>
<tr class="even">
<td>Dataset</td>
<td>~300K tokens</td>
<td>300B tokens</td>
</tr>
<tr class="odd">
<td>Architecture</td>
<td>Nearly identical</td>
<td>Nearly identical</td>
</tr>
</tbody>
</table>
<p>The architecture we built is essentially the same as GPT-3. The difference is pure scale: 17,500x more parameters trained on 1 million times more data. By today’s standards, even GPT-3’s 300B tokens is considered modest. Current models train on 1T+ tokens.</p>
<p>This is what makes the Transformer architecture so remarkable. The same fundamental design (attention for communication, feed-forward for computation, residual connections, layer norm) scales from a 10M parameter Shakespeare generator to a 175B parameter model!</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<ul>
<li><strong>Code</strong>: <a href="https://github.com/garg-aayush/building-from-scratch/tree/main/basic-gpt">building-from-scratch/basic-gpt</a></li>
<li><strong>Video</strong>: <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Let’s Build GPT from Scratch</a> by Andrej Karpathy</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/garg-aayush\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/garg-aayush">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/aayush-garg-8b26a734">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Aayush_ander">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>