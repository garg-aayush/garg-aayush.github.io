---
permalink: /help/
---


## Key takeaways
* In this point I will focus on why LLM pipelines evaluations is hard and matters. Then what is evaluation in terms Shreya and Hamel and why it is important to avoid knee jerk fixes.Evaluation is the systematic measurement of an LLM pipeline’s quality—encompassing safety, reliability, and usefulness—rather than relying on a single metric&#x20;

* In this I will talk about the three challenges with LLM application development in form of three gulfs.Developers must bridge three “gulfs” in LLM pipeline development—Comprehension (understanding data and model failures), Specification (translating intent into precise prompts), and Generalization (ensuring robust behavior on new inputs)&#x20;

* In this i will talk Analyze → Measure → Improve about Effective LLM evaluation follows an iterative Analyze → Measure → Improve lifecycle to systematically uncover, quantify, and address application-specific failures&#x20;

* What LLM strengths and weaknesses are. LLMs bring strengths (fluent text generation, summarization, few-shot learning) but also weaknesses (non-determinism, hallucination, limited algorithmic reasoning) that evaluation must explicitly address&#x20;

* Why it is important to write a good initial prompt. Why iterative refinement matters. A well-specified initial prompt must include: role and objective, clear “do’s and don’ts,” relevant context, few-shot examples, reasoning directives, output formatting constraints, and delimiters to reduce ambiguity&#x20; * Iterative prompt refinement is crucial—first drafts are starting points that must be tested and improved before deep error analysis&#x20;

* What is good and bad behavior as per them. Defining “good” vs. “bad” behavior begins by brainstorming user pain points to derive concrete specifications (what the bot must and must not do)&#x20;

* Different evaluation metrics.Evaluation metrics split into reference-based checks (comparing outputs to known “gold” answers) and reference-free checks (verifying inherent output properties), each suited to different failure modes&#x20;

* Finish with the first most important step in evaluation is Clarifying specification failures (ambiguous prompts) should precede measuring generalization failures, ensuring that metrics focus on true model limitations rather than prompt misunderstandings&#x20; THis is where error analysis becomes your super-power. Robust error analysis—bootstrapping representative traces, open coding to identify failures, and axial coding to cluster them—lays the foundation for meaningful measurement and improvement&#x20;


## Points mentioned by Hamel and Shreya

### Hamel
Hamel's Key Points:

1. On Data Understanding:
"Before jumping to metrics, before jumping to anything else, you have to really look at your data and comprehend it and comprehend your problem specifically enough."

2. On Metrics Selection:
"One of the metrics they used in their EVOLS was edit distance... Actually, that turned out to be a very bad metric."

3. On Annotation Importance:
"You don't want to outsource your annotation... That's just an engineering thing. This EV is an engineering thing only, that's a really big mistake."

4. On Analysis Phase:
"The analyzed phase is probably the most important phase of them all... That's the thing that most people skip, that's the thing where there's probably the least guidance out there in the industry."

5. On Prompt Development:
"You should definitely... pay attention to your prompt... a lot of times I've seen prompts that are clearly that a human hasn't looked at."

6. On User Understanding:
"If you're developing some kind of medical application and you're not a doctor, then you might not really understand what is good and bad. In that case, it's really important that you understand your user quite intimately."

7. On Error Analysis:
"Error analysis is going to be one of your superpowers. It's something that is not really taught anywhere else."

I cannot provide insights from "Shreya" as this person is not identified as a speaker in the provided transcript.

### Shreya

1. On Understanding Data & Queries:
"People are not aware of what are the different types of queries that the products that they're building are going to seem... If you're blind to this, you haven't seen the full variety of user requests, then you can't build an effective product."

2. On Data Volume Challenges:
"If you're building recipe bot, you might get thousands and tens of thousands... of queries that are coming every single day. You can't read all of that text."

3. On Prompt Development Strategy:
"What I like to do when writing a prompt is I like to write a draft of it myself, specifying bullet lists of dos and don'ts... then you can use an LLM to maybe improve the clarity of that."

4. On Generalization Challenges:
"I commonly test queries that the LLM gives a good output, but then it's in production or some other user is working with it and then suddenly that output is wrong... I don't have a great mental model of when the LLM can and can't generalize."

5. On Time Investment in Analysis:
"I ballpark like 75% to 80% of my time I spend in the analyze."

6. On Components of Good Prompts:
- "First, I'd like to start a prompt with the role and the objective"
- "Be very specific, be very unambiguous in what to do and what not to do"
- "Sometimes that could be pulling in recipes from the internet, or maybe you want a personalized experience for the user"

7. On Specifications:
"Specifications are the only place to insert taste. And a model that is trained to solve everybody's problems on every domain... is not going to be able to know everybody's specifications."

8. On Moving Slowly:
"It's very tempting to try to move as quickly as possible with large language models... but it's okay to move slowly. I find that every time I move too fast, I regret it later on."
