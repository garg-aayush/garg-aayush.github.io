<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Aayush Garg</title>
<link>https://garg-aayush.github.io/blog/</link>
<atom:link href="https://garg-aayush.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Personal website</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Wed, 10 Sep 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>A Guide to Building Custom Nodes in ComfyUI</title>
  <link>https://garg-aayush.github.io/posts/2025-09-10-build-custom-comfyui-node.html</link>
  <description><![CDATA[ 




<p><a href="https://www.comfy.org/">ComfyUI</a> is by far my favorite open-source software right now. Its intuitive node-based interface has transformed the way we build AI image and video generation workflows.</p>
<p>What I really appreciate about ComfyUI is its flexibility. You can easily extend it with your own custom nodes. Here, I‚Äôll show you how to create custom nodes that let you add exactly the tools you need. I‚Äôll use parts from my <a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster">Svg2Raster</a> nodes as the running example for this purpose.</p>
<section id="svg2raster" class="level2">
<h2 class="anchored" data-anchor-id="svg2raster"><a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster">Svg2Raster</a></h2>
<p>ComfyUI does not natively support vector graphics like <a href="https://en.wikipedia.org/wiki/SVG">SVGs</a>. I often work with them and needed lightweight nodes to load (SVG-&gt;JPEGs/PNGs) and manipulate SVGs in ComfyUI.</p>
<p>Thus, I built <a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster">Svg2Raster</a>, a small custom node package that makes it easy to use SVGs with other nodes. <img src="https://garg-aayush.github.io/static/img/blog-2025-09-10/workflow.png" class="img-fluid" alt="SVG2Raster"></p>
</section>
<section id="writing-your-custom-comfyui-node" class="level1">
<h1>Writing your Custom ComfyUI Node</h1>
<p>So here I am assuming that you are fairly comfortable using ComfyUI and you already have ComfyUI installed locally on your system/cloud instance.</p>
<section id="step-1-validate-the-core-logic-first" class="level2">
<h2 class="anchored" data-anchor-id="step-1-validate-the-core-logic-first">Step 1: Validate the core logic first</h2>
<p>I prefer not to start with the ComfyUI node API. First, I like to write a simple Python notebook to test the functionalities I actually need. This validates your core code logic and packages in isolation.</p>
<p>In my case, I needed a way to read, rasterize and manipulate the SVGs. Thus, I tested all the relevant operations using the core packages <a href="https://cairosvg.org/">CairoSVG</a> and <a href="https://python-pillow.org/">Pillow</a>.</p>
<p>For example:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simple SVG read and conversion check</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cairosvg</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, ImageOps</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> io</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read SVG file</span></span>
<span id="cb1-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'logo.svg'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb1-8">    svg_text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> f.read()</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Basic conversion to PNG</span></span>
<span id="cb1-11">img_bytes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cairosvg.svg2png(bytestring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>svg_text.encode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>), </span>
<span id="cb1-12">                              output_width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>)</span>
<span id="cb1-13">img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(io.BytesIO(img_bytes)).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RGBA'</span>)</span>
<span id="cb1-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Image size: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>img<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
<p>If you want to see all the code snippets (width/height controls, color and border manipulations etc.), please check out the full <a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster/blob/main/svg2png.ipynb">notebook</a>.</p>
<p><strong>Once you have a working standalone script or code, wrapping it as a ComfyUI node is mostly boilerplate.</strong></p>
</section>
<section id="step-2-understand-the-anatomy-of-a-custom-node" class="level2">
<h2 class="anchored" data-anchor-id="step-2-understand-the-anatomy-of-a-custom-node">Step 2: Understand the Anatomy of a Custom Node</h2>
<p>Every ComfyUI node is a Python class with specific methods that ComfyUI expects. Here are the essential components:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Component</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>INPUT_TYPES</code></td>
<td>What inputs your node accepts</td>
</tr>
<tr class="even">
<td><code>RETURN_TYPES</code></td>
<td>What it outputs to other nodes</td>
</tr>
<tr class="odd">
<td><code>RETURN_NAMES</code></td>
<td>Optional labels for outputs</td>
</tr>
<tr class="even">
<td><code>FUNCTION</code></td>
<td>The method name that runs your logic</td>
</tr>
<tr class="odd">
<td><code>CATEGORY</code></td>
<td>Where it appears in ComfyUI‚Äôs node menu</td>
</tr>
</tbody>
</table>
<p>ComfyUI handles the rest of UI, connections and execution order. For example, this is how a simple custom node class will looks like:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LoadSVG:</span>
<span id="cb2-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@classmethod</span></span>
<span id="cb2-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> INPUT_TYPES(cls):</span>
<span id="cb2-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {</span>
<span id="cb2-5">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: {</span>
<span id="cb2-6">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"svg_file"</span>: (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"STRING"</span>, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"default"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"file.svg"</span>}),</span>
<span id="cb2-7">            }</span>
<span id="cb2-8">        }</span>
<span id="cb2-9">    </span>
<span id="cb2-10">    RETURN_TYPES <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"IMAGE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"STRING"</span>)</span>
<span id="cb2-11">    RETURN_NAMES <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"image"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"svg_text"</span>)</span>
<span id="cb2-12">    FUNCTION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"load_svg"</span></span>
<span id="cb2-13">    CATEGORY <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Svg2Raster"</span></span>
<span id="cb2-14">    </span>
<span id="cb2-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> load_svg(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, svg_file):</span>
<span id="cb2-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Your actual logic here</span></span>
<span id="cb2-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (image_tensor, svg_text)</span></code></pre></div></div>
<p>This is a minimal ComfyUI node class explanation that I believe is good enough to start writing your own nodes. If you want more details, check the official ComfyUI custom node <a href="https://docs.comfy.org/custom-nodes/overview">documentation</a>.</p>
</section>
<section id="step-3-implementing-the-loadsvgimage-node" class="level2">
<h2 class="anchored" data-anchor-id="step-3-implementing-the-loadsvgimage-node">Step 3: Implementing the <strong>LoadSVGImage</strong> Node</h2>
<p>First, I set up the file structure in ComfyUI‚Äôs <code>custom_nodes</code> folder for my nodes package:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> ComfyUI/custom_nodes</span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mkdir</span> svg2raster</span>
<span id="cb3-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> svg2raster</span></code></pre></div></div>
<p>Then I create two essential files:</p>
<p><code>__init__.py</code>: it allows ComfyUI to import your custom nodes.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> .svg2raster_node <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__all__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NODE_CLASS_MAPPINGS"</span>,</span>
<span id="cb4-4">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NODE_DISPLAY_NAME_MAPPINGS"</span>]</span></code></pre></div></div>
<p><code>svg2raster_node.py</code>: this is where the actual nodes code is written.</p>
<p>You can find the <strong>complete code</strong> for these nodes here: <a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster/blob/main/svg2raster_node.py">svg2raster_node.py</a>. Here‚Äôs the boilerplate structure of <strong>LoadSVGImage</strong> node:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LoadSVGImage:</span>
<span id="cb5-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@classmethod</span></span>
<span id="cb5-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> INPUT_TYPES(cls):</span>
<span id="cb5-4">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Define what inputs this node accepts"""</span></span>
<span id="cb5-5">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use `folder_paths` to access ComfyUI's input directory</span></span>
<span id="cb5-6">        input_dir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> folder_paths.get_input_directory()</span>
<span id="cb5-7">        files <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [f <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> os.listdir(input_dir) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> os.path.isfile(os.path.join(input_dir, f)) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> f.lower().endswith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.svg'</span>)]</span>
<span id="cb5-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {</span>
<span id="cb5-9">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"required"</span>: {</span>
<span id="cb5-10">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"svg"</span>: (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(files), {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"image_upload"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>}),</span>
<span id="cb5-11">            }</span>
<span id="cb5-12">        }</span>
<span id="cb5-13">    </span>
<span id="cb5-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output configuration</span></span>
<span id="cb5-15">    RETURN_TYPES <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"STRING"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"IMAGE"</span>)</span>
<span id="cb5-16">    RETURN_NAMES <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"svg_text"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"preview_image"</span>)</span>
<span id="cb5-17">    FUNCTION <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"load_svg"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Method name to execute</span></span>
<span id="cb5-18">    CATEGORY <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FromSVG/Tools"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Menu location</span></span>
<span id="cb5-19">    </span>
<span id="cb5-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> load_svg(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, svg, background<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#FFFFFF"</span>):</span>
<span id="cb5-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Main execution method - does the actual work"""</span></span>
<span id="cb5-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Your logic here</span></span>
<span id="cb5-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (svg_text, image_tensor)</span>
<span id="cb5-24">    </span>
<span id="cb5-25">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@classmethod</span></span>
<span id="cb5-26">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> IS_CHANGED(cls, svg):</span>
<span id="cb5-27">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Returns file hash or modification time</span></span>
<span id="cb5-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">pass</span></span>
<span id="cb5-29">    </span>
<span id="cb5-30">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@classmethod</span></span>
<span id="cb5-31">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> VALIDATE_INPUTS(cls, svg):</span>
<span id="cb5-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if file exists, return error string if invalid</span></span>
<span id="cb5-33">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span></code></pre></div></div>
<p>Here, the helper methods serve crucial purposes: - <strong><code>IS_CHANGED</code></strong>: Tells ComfyUI when to re-execute the node - <strong><code>VALIDATE_INPUTS</code></strong>: Prevents crashes by validating inputs before execution</p>
<p>ComfyUI expects images as tensors in BHWC format (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channels</code>) with values normalized to 0-1. Thus, you need to have a pil to tensor function.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _pil_to_tensor(pil_img: Image.Image):</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Convert PIL image to ComfyUI IMAGE tensor: (B, H, W, C) in [0,1]"""</span></span>
<span id="cb6-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># conversion logic</span></span></code></pre></div></div>
<p>Finally, you need the mappings for ComfyUI to discover your nodes:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">NODE_CLASS_MAPPINGS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb7-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LoadSVGImage"</span>: LoadSVGImage,</span>
<span id="cb7-3">}</span>
<span id="cb7-4">NODE_DISPLAY_NAME_MAPPINGS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb7-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LoadSVGImage"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Load SVG Image"</span>,</span>
<span id="cb7-6">}</span></code></pre></div></div>
<p>Without these mappings, ComfyUI won‚Äôt find your nodes even if the code is correct.</p>
<p>Similarly, I also wrote a <code>RasterizeSVG</code> class for manipulating the loaded SVG. It takes the SVG text from <code>LoadSVGImage</code> and lets you adjust scale, dimensions, borders, and more. You will see the pattern is identical: define inputs, process with CairoSVG/PIL, convert to tensor, return.</p>
<p>That‚Äôs how you implement a node. Write a standalone functionality script, wrap it in the ComfyUI class structure, handle the tensor conversions, add the helper methods, and register it with the mappings.</p>
</section>
<section id="step-4-testing-your-custom-node-in-comfyui" class="level2">
<h2 class="anchored" data-anchor-id="step-4-testing-your-custom-node-in-comfyui">Step 4: Testing Your Custom Node in ComfyUI</h2>
<p>Once you are done implementing, testing is straightforward.</p>
<ol type="1">
<li>Ensure all your dependencies are installed, including <code>CairoSVG</code>:</li>
<li>Restart ComfyUI for it to detect the new node.</li>
<li>Find your nodes under the defined category</li>
</ol>
<p><strong>Note</strong>: I have also added the installation steps <a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster?tab=readme-ov-file#installation">here</a>.</p>
</section>
<section id="step-5-sharing-and-publishing-your-node" class="level2">
<h2 class="anchored" data-anchor-id="step-5-sharing-and-publishing-your-node">Step 5: Sharing and Publishing Your Node</h2>
<p>Once everything worked, I created a GitHub repo for the nodes. You can see how I structured mine in the <a href="github.com/garg-aayush/ComfyUI-Svg2Raster">Svg2Raster</a> repo.</p>
<p>Some Essential files in the repo are:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>README.md</td>
<td>Clear installation instructions and usage examples</td>
</tr>
<tr class="even">
<td>requirements.txt</td>
<td>Python dependencies (cairosvg in my case)</td>
</tr>
<tr class="odd">
<td>pyproject.toml</td>
<td>Required if you plan to publish to ComfyUI Registry</td>
</tr>
<tr class="even">
<td>examples/</td>
<td>Optional Sample SVG files and workflow JSON files</td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>: Having a good Readme and examples makes a huge difference for users trying to understand and use your nodes.</p>
<p>Once your repo is ready, you can even publish it to the <a href="https://registry.comfy.org/nodes/svg2raster">ComfyUI Registry</a>. There‚Äôs an excellent guide on <a href="https://docs.comfy.org/registry/publishing">publishing to ComfyUI Registry</a> - just follow those steps.</p>
<p>I also set up a GitHub Actions workflow that automatically publishes updates to the ComfyUI Registry whenever I push changes to my repo. This ensures the registry always has the latest version. You can check out my <a href="https://github.com/garg-aayush/ComfyUI-Svg2Raster/blob/main/.github/workflows/publish.yaml">workflow file</a> to see how I did it.</p>


</section>
</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2025-09-10-build-custom-comfyui-node.html</guid>
  <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Key Takeaways from Lecture 1: LLM Evaluation Lifecycle</title>
  <link>https://garg-aayush.github.io/posts/2025-09-02-llm-evaluation-lifecycle.html</link>
  <description><![CDATA[ 




<p>A couple of months back, I enrolled in <a href="https://maven.com/parlance-labs/evals">AI Evals for Engineers and PMs</a>, a course by <a href="https://hamel.dev/">Hamel</a> and <a href="https://www.sh-reya.com/">Shreya</a>. The live cohort for ot ran from July to mid-August, but due to work commitments I couldn‚Äôt follow along in real time.</p>
<p>I have now started following it as a self-paced course and plans to write a blog for each lesson as I progress. This will be my way to capture what I learn and to reflect on the material. In this first blog ü§û, I‚Äôll walk through my key takeaways from introductory <strong>Lecture 1</strong>.</p>
<section id="key-takeaways" class="level1">
<h1>Key Takeaways</h1>
<section id="evaluation-isnt-optional-but-fundamental" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-isnt-optional-but-fundamental">1. Evaluation isn‚Äôt Optional but Fundamental</h2>
<p>Anyone who has built or worked with LLM pipelines knows that their outputs are open-ended, subjective, and unstructured (unless you enforce it). If you rely on ad-hoc checks which I have been guilty of, it often leads to knee-jerk fixes. Moreover, it completely miss the long-term need of continuous tracking which is essential for improving your pipeline reliability and usefulness. This is why <strong>Evaluation‚Äîthe systematic measurement of an LLM pipeline quality‚Äîis critical!</strong></p>
</section>
<section id="the-three-gulfs" class="level2">
<h2 class="anchored" data-anchor-id="the-three-gulfs">2. The Three Gulfs</h2>
<p>The below image beautifully captures and categorizes the challenges associated with any LLM application: <img src="https://garg-aayush.github.io/static/img/blog-2025-09-02/three-gulfs.png" class="img-fluid" alt="Three gulfs"></p>
<ul>
<li><p><strong>Gulf of Comprehension</strong>: This is a result of limited understanding of the input data (user queries) and the pipeline‚Äôs outputs (behavior). Bridging it requires examining examples to identify common failure modes. This brings it own challenge: <strong>‚ÄúHow to manually review every input or output to identify failure modes?‚Äù</strong></p></li>
<li><p><strong>Gulf of Specification</strong>: It refers to the difficulty of translating a user‚Äôs high-level intent into unambiguous precise instructions for the LLM. Bridging it requires writing detailed prompts that captures ‚Äútrue intent‚Äù which in itself is challenging due to <strong>ambiguous nature of natural language.</strong></p></li>
<li><p><strong>Gulf of Generalizaton</strong>: This is due to LLMs unexpected and inconsistent behavior on new or unusual (out of distribution) inputs. Bridging it requires a good understanding of your LLM model capabilities. This leads to the question: <strong>‚ÄúHow to improve LLM model?‚Äù</strong></p></li>
</ul>
</section>
<section id="analyze-measure-improve-lifecycle" class="level2">
<h2 class="anchored" data-anchor-id="analyze-measure-improve-lifecycle">3. Analyze ‚Üí Measure ‚Üí Improve Lifecycle</h2>
<p>Hamel and Shreya introduced a structured way to bridge the above gulfs: <strong>Analyze ‚Üí Measure ‚Üí Improve</strong> lifecycle.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2025-09-02/pitfalls.png" class="img-fluid figure-img"></p>
<figcaption>Analyze ‚Üí Measure ‚Üí Improve Lifecycle</figcaption>
</figure>
</div>
<p>However, the most important takeaways for me was not what each phase means but the <strong>pitfalls</strong> that often derail them:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 48%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>Phase</th>
<th>Pitfalls</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Analyze</strong></td>
<td>Outsourcing annotation; looking at too few examples and forming shaky hypotheses</td>
<td>This is where you learn the most. Spend <strong>~75‚Äì80%</strong> of your time here‚Äîgood analysis sets up everything else.</td>
</tr>
<tr class="even">
<td><strong>Measure</strong></td>
<td>Misaligned or poorly designed LLM judges; ‚Äúoverfitting‚Äù by testing judges on the same examples used in the judge prompt</td>
<td>In this phase, you need the rigor of data science. <strong>NEVER</strong> leak test data into judge prompts.</td>
</tr>
<tr class="odd">
<td><strong>Improve</strong></td>
<td>Prematurely jumping to fixes; defaulting to the most complex solution first (fine-tuning, bigger models)</td>
<td><strong>Start simple</strong>. Prompt tweaks and improvements often go a long way before heavier changes are needed.</td>
</tr>
</tbody>
</table>
</section>
<section id="llms-are-imperfectprompt-iteratively" class="level2">
<h2 class="anchored" data-anchor-id="llms-are-imperfectprompt-iteratively">4. LLMs are Imperfect‚ÄîPrompt Iteratively</h2>
<p>When we write prompts it‚Äôs easy to ignore that LLMs are non-deterministic, prompt-sensitive and can confidently hallucinate. Thus, always remember: <strong><em>‚ÄúLLMs are powerful but imperfect components. Leverage strengths, anticipate weaknesses.‚Äù</em></strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2025-09-02/llm-strengths-weaknesses.jpg" class="img-fluid figure-img"></p>
<figcaption>LLM Strengths vs.&nbsp;Weaknesses</figcaption>
</figure>
</div>
<p><strong>Effective prompting starts with you.</strong> You should not delegate the prompting to an LLM or you will miss important failure modes. Instead, write your own draft prompt and if needed, use an LLM only to polish clarity.</p>
<p>From there on, treat prompting as an iterative process where the first draft is a starting point which you refine based on observed outputs.</p>
</section>
<section id="reference-based-vs-reference-free-metrics" class="level2">
<h2 class="anchored" data-anchor-id="reference-based-vs-reference-free-metrics">5. Reference-based vs Reference-free Metrics</h2>
<p>The evaluation metrics broadly fall into two categories: <strong>reference-free</strong> and <strong>reference-based</strong>. Both of them are useful but in different contexts.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Reference-Free</strong></th>
<th><strong>Reference-Based</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>What it means</strong></td>
<td>Evaluates properties of the output itself (no golden answer required)</td>
<td>Compares output against a golden reference or ground truth</td>
</tr>
<tr class="even">
<td><strong>When to use</strong></td>
<td>Creative or open-ended tasks, formatting/structure checks, validity tests</td>
<td>Tasks with clearly defined correct answers (e.g., factual QA, deterministic outputs)</td>
</tr>
<tr class="odd">
<td><strong>Examples</strong></td>
<td>- Does the output follow the JSON format?<br>- Does generated code/SQL run without errors?</td>
<td>- Exact match against a gold SQL query<br>- ROUGE/BLEU score for text generation</td>
</tr>
</tbody>
</table>


</section>
</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2025-09-02-llm-evaluation-lifecycle.html</guid>
  <pubDate>Tue, 02 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Part III: Fine-tuning Llama-3-8B for Structured Functional Representation Extraction</title>
  <link>https://garg-aayush.github.io/posts/2024-07-15-finetune-llama3-8B-predibase.html</link>
  <description><![CDATA[ 




<p>Last week, I published the <a href="https://aayushgarg.dev/2024-07-09-compare-models-structured-data/">second blog</a> in my LLM fine-tuning series, comparing various models performance in functional representation extraction.</p>
<p>In this third part of the series, I discuss the <strong>first steps toward fine-tuning an (open-source)-LLM for functional representation extraction</strong>. My aim is to give you all a sneak peek at the kind of performance you can expect from fine-tuning an LLM for a custom task. To streamline this step (and to satisfy my own curiosity üòä), I will use <a href="https://predibase.com/">Predibase</a>. It is a fast, cheap, and efficient open-source LLM fine-tuning and deployment platform.</p>
<blockquote class="blockquote">
<p>FYI: I have some free Predibase credits through Dan‚Äôs and Hamel‚Äôs LLM course. Therefore, it is a perfect opportunity to put those credits to good use! üò¨</p>
</blockquote>
<blockquote class="blockquote">
<p>Note: Whenever I mention ‚Äúfinetuning LLM,‚Äù I am specifically referring to LoRA (Low-Rank Adaptation) finetuning of a Large Language Model. For overview of LoRA, please read Sebastian Raschka‚Äôs blogs (<a href="https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html">LORA Blog 1</a>, <a href="https://magazine.sebastianraschka.com/p/llm-research-insights-instruction">LORA Blog 2</a>).</p>
</blockquote>
<section id="task-and-dataset" class="level2">
<h2 class="anchored" data-anchor-id="task-and-dataset">Task and Dataset</h2>
<p>Similar to my previous blogs, the custom task is to predict the structured functional representation from the given text video game opinions of the <a href="https://huggingface.co/datasets/GEM/viggo">ViGGO validation dataset</a>.</p>
<p><strong>To make this exercise interesting and challenging for future experiments, I will use a maximum of 1000 examples for fine-tuning any LLM model, instead of the full ~5K train dataset</strong>.</p>
<p>Below is an example from the randomly selected <code>1K</code> train dataset:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">Text                      : I remember you saying that you loved The Room. Do you tend to enjoy PC games <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2012</span>?</span>
<span id="cb1-2">functional_representation : verify_attribute(name[The Room], release_year[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2012</span>], rating[excellent], platforms[PC])</span></code></pre></div></div>
<p>As shown in the graph below, the selected <code>1K</code> dataset is a fairly representative sample of the full ViGGO train dataset.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/viggo_function_name_distribution_1K.png" class="img-fluid figure-img"></p>
<figcaption>Understanding Data Distribution</figcaption>
</figure>
</div>
</section>
<section id="upload-the-dataset-to-predibase" class="level2">
<h2 class="anchored" data-anchor-id="upload-the-dataset-to-predibase">Upload the dataset to Predibase</h2>
<p>Predibase requires you to upload the instruction fine-tuning dataset in particular format. This is from <a href="https://docs.predibase.com/user-guide/fine-tuning/prepare-data#how-to-structure-your-dataset">Predibase docs</a>:</p>
<blockquote class="blockquote">
<p>For instruction fine-tuning, your dataset must contain two columns named prompt and completion: - prompt: Your input prompt. It serves as the starting point or the guiding information for the model. - completion: The expected response that corresponds to the input provided in the ‚Äúprompt‚Äù column. - split (optional): Should be either train or evaluation. To learn more, check out this section.</p>
</blockquote>
<p><strong>Make sure to add the prompt template to the examples and convert them to the correct format.</strong> For this exercise, I use the following prompt template:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""Given a target sentence convert it structured functional representation.</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">### Target sentence: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{text}</span></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">### Output Functional representation:</span></span>
<span id="cb2-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div></div>
<p>You can connect your dataset to Predibase via the UI or Python SDK. Here, I will upload the dataset using SDK.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize Predibase client</span></span>
<span id="cb3-2">pb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Predibase(api_token<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PREDIBASE_API_TOKEN"</span>])</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Upload the dataset</span></span>
<span id="cb3-5">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pb.datasets.from_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"viggo_train_val_dataset_1K.csv"</span>, </span>
<span id="cb3-6">                                name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"viggo_train_val_dataset_1K"</span>)</span></code></pre></div></div>
<p>Once uploade, you can check the uploaded dataset on the Predibase UI. <img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/predibase_ui_dataset.png" class="img-fluid" alt="Dataset"> <img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/predibase_ui_dataset2.png" class="img-fluid" alt="Dataset"></p>
<p>For detailed steps on uploading the dataset to Predibase, please refer to the companion <a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Finetune_llama-3-8b_Predibase.ipynb">blog notebook</a>.</p>
</section>
<section id="setup-and-finetune" class="level2">
<h2 class="anchored" data-anchor-id="setup-and-finetune">Setup and Finetune</h2>
<p>Once you have uploaded the dataset, running the fine-tuning process is refreshingly simple. For this example, I fine-tune the base <code>llama-3-8b</code> model with the following parameters: <code>epochs=3</code>, <code>rank=16</code>, and <code>learning_rate=2e-4</code>.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create an adapter repository</span></span>
<span id="cb4-2">repo <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pb.repos.create(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"viggo-finetune-1K"</span>, </span>
<span id="cb4-3">                description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Llama-3-8b adapter repository for viggo 1K examples"</span></span>
<span id="cb4-4">                )</span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create and run the fine-tuning job</span></span>
<span id="cb4-7">adapter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pb.adapters.create(</span>
<span id="cb4-8">   config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>FinetuningConfig(</span>
<span id="cb4-9">       base_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llama-3-8b"</span>,</span>
<span id="cb4-10">       epochs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb4-11">       rank<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>,</span>
<span id="cb4-12">       learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0002</span>,</span>
<span id="cb4-13">   ),</span>
<span id="cb4-14">   dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dataset,</span>
<span id="cb4-15">   repo<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>repo,</span>
<span id="cb4-16">   description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"baseline-llama-3-8b"</span>,</span>
<span id="cb4-17">)</span></code></pre></div></div>
<p>That‚Äôs all you need to do to submit a job! Once completed, it will be available on the Predibase platform.</p>
<p><img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/predibase_ui_train1.png" class="img-fluid" alt="train-1"> <img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/predibase_ui_train2.png" class="img-fluid" alt="train-2"></p>
<p>You can always tweak multiple hyperparameters (see <a href="https://docs.predibase.com/sdk-guide/SDKv2/ConfigClasses/FineTuningConfig">Finetuning Config</a>) and run the fine-tune job again. All your fine-tune jobs will be available on the Predibase platform.</p>
</section>
<section id="evaluate-the-fine-tuned-model" class="level2">
<h2 class="anchored" data-anchor-id="evaluate-the-fine-tuned-model">Evaluate the Fine-tuned Model</h2>
<p>Predibase provides both popular <code>Serverless endpoints</code> and <code>Dedicated deployments</code> options for opens-source LLMs and their fine-tuned LORA checkpoints. I will create serverless endpoint for this case.</p>
<blockquote class="blockquote">
<p>Note, atleast for now, <a href="https://docs.predibase.com/user-guide/inference/serverless_endpoints">serverless deployments</a> are available for free.</p>
</blockquote>
<section id="generate-the-responses-for-validation-dataset" class="level3">
<h3 class="anchored" data-anchor-id="generate-the-responses-for-validation-dataset">Generate the responses for validation dataset</h3>
<p>Similar to my previous blogs, I will evaluate the finetuned model on ViGGO <code>validation</code> dataset and calculate custom <a href="https://aayushgarg.dev/2024-07-09-compare-models-structured-data/">performance metrics</a> metrics for a better understanding of finetuned model performance.</p>
<p>First, I generate the responses for the validation dataset:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the Predibase deployment client</span></span>
<span id="cb5-2">lorax_client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pb.deployments.client(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llama-3-8b"</span>)</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the validation dataset</span></span>
<span id="cb5-5">viggo_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"GEM/viggo"</span>)</span>
<span id="cb5-6">val_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> viggo_dataset[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'validation'</span>]</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># finetuned adapter id</span></span>
<span id="cb5-9">adapter_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"viggo-finetune-1K/2"</span> </span>
<span id="cb5-10"></span>
<span id="cb5-11">responses_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb5-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(val_dataset)):</span>
<span id="cb5-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Processing </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(val_dataset)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb5-14">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lorax_client.generate(prompt_template.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>val_dataset[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"target"</span>][idx]), adapter_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"viggo-finetune-1K/2"</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>).generated_text</span>
<span id="cb5-15">    ground_truth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> val_dataset[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"meaning_representation"</span>][idx]</span>
<span id="cb5-16">    text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> val_dataset[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"target"</span>][idx]</span>
<span id="cb5-17">    responses_dict[idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>: output, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ground_truth"</span>: ground_truth, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: text}</span></code></pre></div></div>
<p><strong>Note: Remember to replace ‚Äúviggo-finetune-1K/2‚Äù with the correct adapter ID. You can find the adapter ID in the Predibase dashboard.</strong></p>
<p>Now, I can generate the evaluation scores using custom evaluation metrics and compare them with previously calculated GPT-4 and Claude 3.5 Sonnet scores:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/finetuned_llama-3-8B_baseline.png" class="img-fluid figure-img"></p>
<figcaption>plot-finetuned-model</figcaption>
</figure>
</div>
<p>The initial finetuning of LLaMA-3-8B using 1,000 random examples from the ViGGO dataset, while not surpassing GPT-4 and Claude 3.5 Sonnet, shows promising results and outperforms several models from our previous blog. Notably, the exact_match score is even better than that of the two best-performing models.</p>
</section>
</section>
<section id="improved-performance-with-updated-prompt-template" class="level2">
<h2 class="anchored" data-anchor-id="improved-performance-with-updated-prompt-template">Improved Performance with Updated Prompt Template</h2>
<p>A simple yet effective way to enhance the model‚Äôs performance is by refining the prompt template. By providing clearer instructions that convey the structure of the functional representation, we can guide the model to produce more accurate outputs.</p>
<p>I updated the prompt template as follows:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""Given a target sentence construct the underlying meaningful functional representation of the input sentence as a single function with attributes and attribute values.</span></span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">### Target sentence: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{text}</span></span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">### Output Functional representation:</span></span>
<span id="cb6-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div></div>
<p>After uploading this new dataset, finetuning the model, and evaluating it with the new adapter <code>viggo-finetune-1K/3</code>, there is significantly improved evaluation metrics. Notably, the model now surpasses GPT-4o‚Äôs scores for <code>exact_match</code> and <code>function_name_match</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2024-07-15/finetuned_llama-3-8B_update1.png" class="img-fluid figure-img"></p>
<figcaption>plot-finetuned-model</figcaption>
</figure>
</div>
<p><strong>This improvement highlights the importance of clear and specific instructions in prompt engineering, even when working with finetuned models.</strong></p>
</section>
<section id="conclusions.." class="level2">
<h2 class="anchored" data-anchor-id="conclusions..">Conclusions..</h2>
<ul>
<li><p>First of all, <strong>My overall experience with Predibase has been positive, particularly in terms of rapid finetuning of models</strong>. While there are some limitations such as restricted hyperparameter tuning, standardized dataset format, and inability to download adapters in the developer tier, it offers a user-friendly platform for fine-tuning (LORA) large language models. I was able to quickly upload, setut, finetune and infer the llm models.</p></li>
<li><p>I achieve out-of-the-box performance using only random <code>1K</code> examples. Although the fine-tuned llama-3-8b model doesn‚Äôt match the performance of GPT-4 and Sonnet 3.5 on all metrics. <strong>This demonstrates the potential of fine-tuning with limited data, highlighting the efficiency of the approach for task-specific model adaptation.</strong></p></li>
</ul>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps‚Ä¶</h2>
<ul>
<li>My next goal is to further enhance the model‚Äôs performance on evaluation metrics while maintaining a limit of 1,000 training examples. <em><strong><a href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment</a></strong> paper has demonstrated in the past that even 1,000 well-curated examples can lead to strong finetuning performance.</em></li>
<li>Careful curated selection of examples and hyerparameters will definitely improve the performance benchmarks on evaluation metrics.</li>
<li>In addition to it, I will deep dive into one of my favorite LLM fine-tuning tools, <a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a>.</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://aayushgarg.dev/2024-07-03-baseline-gpt4o-structured-data/">Part II blog post of series</a></li>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Analyze_Viggo_Dataset.ipynb">Notebook I: Analyze_Viggo_Dataset.ipynb</a></li>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Finetune_llama-3-8b_Predibase.ipynb">Notebook II: Finetune_llama-3-8b_Predibase.ipynb</a></li>
<li><a href="https://predibase.com/">Predibase Platform</a></li>
<li><a href="https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html">LORA blog I: Finetuning Large Language Models (LLMs)</a></li>
<li><a href="https://magazine.sebastianraschka.com/p/llm-research-insights-instruction">LORA blog II: LLM Research Insights: Instruction Tuning &amp; Training Paradigms</a></li>
<li><a href="https://llama.meta.com/llama3/">Llama 3</a></li>
<li><a href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment</a></li>
<li><a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl: A Framework for Fine-tuning LLMs</a></li>
</ul>
<hr>
<p>Thanks for reading! If you have any questions or feedback, please let me know on <a href="https://twitter.com/Aayush_ander">Twitter</a> or <a href="https://www.linkedin.com/in/aayush-garg-8b26a734/">LinkedIn</a>.</p>


</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2024-07-15-finetune-llama3-8B-predibase.html</guid>
  <pubDate>Mon, 15 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Part II: Comparison of Model Performances on Structured Functional Representation Extraction</title>
  <link>https://garg-aayush.github.io/posts/2024-07-09-compare-models-structured-data.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>In the <a href="https://aayushgarg.dev/2024-07-03-baseline-gpt4o-structured-data/">previous blog post</a>, I established a performance baseline using GPT-4o for generating structured data, particularly functional representations, from text using the <a href="https://huggingface.co/datasets/GEM/viggo">ViGGO Dataset</a>.</p>
<p>Building on that foundation, I expand the experiment to include a broader range of models, both open-source and proprietary. This comparison aims to provide insights on how well these models perform out of the box in structured data extraction tasks, which is quite crucial for RAG applications, knowledge base construction, and reasoning systems.</p>
<p>I evaluate and compare the performance of these six LLM models:</p>
<ol type="1">
<li><p><a href="https://openai.com/index/hello-gpt-4o/">GPT-4o</a>: OpenAI‚Äôs latest iteration of the GPT-4 model, known for its faster generation, advanced natural language understanding and generation capabilities. Currently one of the most popular and capable models.</p></li>
<li><p><a href="https://www.anthropic.com/news/claude-3-5-sonnet">Claude Sonnet-3.5</a>: Anthropic‚Äôs refined language model with enhanced reasoning abilities. It aims to provide more context-aware outputs compared to earlier versions and has recently outperformed GPT-4o on many benchmarks.</p></li>
<li><p><a href="https://deepmind.google/technologies/gemini/flash/">Gemini-1.5-Flash</a>: Google DeepMind‚Äôs streamlined version of the Gemini model, optimized for faster inference and reduced computational requirements.</p></li>
<li><p><a href="https://replicate.com/meta/meta-llama-3-70b-instruct">llama-3-70b-instruct</a>: Meta‚Äôs large-scale instruction-tuned language model, part of the latest LLaMA 3 family, with 70 billion parameters. It‚Äôs designed to follow complex instructions and generate high-quality text across diverse domains.</p></li>
<li><p><a href="https://replicate.com/mistralai/mixtral-8x7b-instruct-v0.1">mixtral-8x7b-instruct-v0.1</a>: Mistral AI‚Äôs instruction-tuned variant of the Mixtral 8x7B model, known for its mixture-of-experts architecture.</p></li>
<li><p><a href="https://replicate.com/meta/meta-llama-3-8b-instruct">llama-3-8b-instruct</a>: A more compact version of Meta‚Äôs LLaMA 3 family, with 8 billion parameters, optimized for instruction following.</p></li>
</ol>
<blockquote class="blockquote">
<p><strong>Note</strong>: I‚Äôve included the smaller <code>Llama-3-8B</code> model as I plan to finetune it‚Äôs base 8B model in coming days. It would help me compare the general instruction finetuned 8B model performance.</p>
</blockquote>
</section>
<section id="dataset-and-prompt-template" class="level3">
<h3 class="anchored" data-anchor-id="dataset-and-prompt-template">Dataset and Prompt Template</h3>
<p>For consistency and fair comparison, I used the same ViGGO validation dataset and the prompt template as in the previous blog post. The prompt template and the few-shot examples are designed to guide the models in generating structured functional representations from the given text input:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">PROMPT_TEMPLATE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values. </span></span>
<span id="cb1-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].</span></span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come before the 'exp_release_date' attribute, and so forth.</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">For each attribute, fill in the corresponding value of the attribute within brackets. A couple of examples are below. Note: you are to output the string after "Output: ". Do not include "Output: " in your answer.</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 1)</span></span>
<span id="cb1-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.</span></span>
<span id="cb1-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: inform(name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no])</span></span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 2) </span></span>
<span id="cb1-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Were there even any terrible games in 2014?</span></span>
<span id="cb1-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: request(release_year[2014], specifier[terrible])</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 3)</span></span>
<span id="cb1-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Adventure games that combine platforming and puzzles  can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.</span></span>
<span id="cb1-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: give_opinion(name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view])</span></span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 4)</span></span>
<span id="cb1-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?</span></span>
<span id="cb1-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: recommend(name[The Wolf Among Us], developer[Telltale Games])</span></span>
<span id="cb1-24"></span>
<span id="cb1-25"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 5) </span></span>
<span id="cb1-26"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Layers of Fear, the indie first person point-and-click adventure game?</span></span>
<span id="cb1-27"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: confirm(name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person])  </span></span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 6) </span></span>
<span id="cb1-30"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: I bet you like it when you can play games on Steam, like Worms: Reloaded, right?  </span></span>
<span id="cb1-31"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: suggest(name[Worms: Reloaded], available_on_steam[yes])</span></span>
<span id="cb1-32"></span>
<span id="cb1-33"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 7)</span></span>
<span id="cb1-34"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?    </span></span>
<span id="cb1-35"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: verify_attribute(name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo])</span></span>
<span id="cb1-36"></span>
<span id="cb1-37"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 8)</span></span>
<span id="cb1-38"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: So what is it about the games that were released in 2005 that you find so excellent?  </span></span>
<span id="cb1-39"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: request_explanation(release_year[2005], rating[excellent])</span></span>
<span id="cb1-40"></span>
<span id="cb1-41"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 9)</span></span>
<span id="cb1-42"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Do you think Mac is a better gaming platform than others?</span></span>
<span id="cb1-43"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: request_attribute(has_mac_release[])</span></span>
<span id="cb1-44"></span>
<span id="cb1-45"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Give the output for the following sentence:</span></span>
<span id="cb1-46"><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{input}</span></span>
<span id="cb1-47"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div></div>
</section>
<section id="generating-the-responses" class="level3">
<h3 class="anchored" data-anchor-id="generating-the-responses">Generating the responses</h3>
<p>I used the respective official API calls for the closed models (<code>GPT-4o</code>, <code>Gemini-1.5-flash</code>, <code>Claude-1.5-Sonnet</code>) and the <a href="https://replicate.com/">Replicate</a> API client for open-source models (<code>Llama-3-70B</code>, <code>Llama-3-8B</code>, <code>Mistral-8x7B</code>).</p>
<p><strong>For detailed information on API endpoints and the process of generating responses for all models, please refer to the <a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Generate_responses_all_llms.ipynb">Generate_responses_all_llms.ipynb</a> notebook.</strong></p>
<p>Generating responses for this experiment had the following associated costs:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model/API</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GPT-4o API</td>
<td>~ $2.5</td>
</tr>
<tr class="even">
<td>Claude-1.5-Sonnet API</td>
<td>~ $3.5</td>
</tr>
<tr class="odd">
<td>Replicate API</td>
<td>~ $3</td>
</tr>
<tr class="even">
<td>Gemini-1.5-flash API</td>
<td>Free*</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td><strong>~$9</strong></td>
</tr>
</tbody>
</table>
<p>_*for limited usage_</p>
</section>
<section id="evaluation-strategy" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-strategy">Evaluation Strategy</h3>
<p>To assess the models‚Äô performance, I used the same evaluation criteria as in the <a href="https://aayushgarg.dev/2024-07-03-baseline-gpt4o-structured-data/">previous post</a>:</p>
<ol type="1">
<li><strong>Function Name Match</strong>: The function name must match the ground truth function name.</li>
<li><strong>Function and Attributes Match</strong>: The generated function name and attributes must match the ground truth function attributes. However, the order of the attributes does not matter.</li>
<li><strong>Function, Attributes, and Values Match</strong>: The generated function name, attributes, and values must match the ground truth function attributes and values. The order of the attributes and values does not matter.</li>
<li><strong>Exact Match</strong>: The generated function must exactly match the ground truth function.</li>
</ol>
<p><strong>Note</strong>: I implemented custom Python functions using regex and string manipulation to calculate these metrics, rather than relying on another LLM for evaluation. This approach helps avoid potential biases that might be introduced by using an LLM in the evaluation process.</p>
<p><strong>For the complete evaluation code and functions used, please refer to the <a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Compare_model_performances.ipynb">Compare_models_performances.ipynb</a> notebook.</strong></p>
</section>
<section id="comparing-the-models-performance" class="level3">
<h3 class="anchored" data-anchor-id="comparing-the-models-performance">Comparing the models performance</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2024-07-09/all_metrics_comparison.png" class="img-fluid figure-img"></p>
<figcaption>Compare Models Performance</figcaption>
</figure>
</div>
<p><strong>Based on the evaluation metric plot</strong>:</p>
<ol type="1">
<li><code>Claude Sonnet-3.5</code> and <code>GPT-4o</code> consistently outperform other models across all metrics.</li>
<li><code>Claude Sonnet-3.5</code> performs better than <code>GPT-4o</code>, aligning with all the twitter chats about its superior performance.</li>
<li><code>Gemini-1.5-Flash</code>, despite its optimization for speed, maintains competitive performance for less stringent metrics but struggles significantly with exact matches.</li>
<li>The performance gap between the top-performing models and others widens sharply for more stringent metrics.</li>
<li>As expected, the smaller <code>Llama-3-8B</code> model shows the lowest performance, highlighting the evident size advantage of larger models.</li>
<li><code>Mistral-8x7B's</code> performance is lower than anticipated, suggesting lower instruction-following capabilities.</li>
</ol>
<p><strong>Some key observations</strong></p>
<blockquote class="blockquote">
<p>Based on the quickly eyeballing the generated responses:</p>
</blockquote>
<ol type="1">
<li>Almost all models consistently captures straightforward attributes such as player perspective and multiplayer status.</li>
<li>For queries involving multiple attributes or conditions, the model sometimes misses or misinterprets parts of the input.</li>
<li>The models struggles with capturing subtle distinctions in opinions and inferring information that is implied but not explicitly stated in the text. For example, models struggled to differentiate between <code>inform</code>, <code>give_opinion</code> and <code>suggest</code>.</li>
</ol>
</section>
<section id="conclusions" class="level3">
<h3 class="anchored" data-anchor-id="conclusions">Conclusions</h3>
<p>This comparison provides valuable insights into the capabilities of various LLMs in functional representation extraction. As expected, the proprietary large models like <code>Claude Sonnet-3.5</code> and <code>GPT-4o</code> perform best out of the box, with <code>Claude Sonnet-3.5</code> being the best.</p>
<p>One can argue that these results may not fully represent the models‚Äô maximum capabilities. Different model-specific prompt engineering approaches or dynamic few-shot examples could potentially improve performance further. However, my aim is just to assess how well a model perform without fancy RAG/function calling/complicated prompt engineering approaches.</p>
</section>
<section id="next-steps." class="level3">
<h3 class="anchored" data-anchor-id="next-steps.">Next steps‚Ä¶.</h3>
<ul>
<li><p>I plan to fine-tune the base <code>Llama-3-8B</code> and other smaller models (like <code>Phi</code> and <code>Gemma</code>) on the ViGGO dataset to assess whether a fine-tuned smaller model can compete with or surpass the performance of <code>Claude Sonnet-3.5</code> and <code>GPT-4o</code>.</p></li>
<li><p>At the same time, investigate the trade offs like inference speed, accuracy, and latency associated with fine-tuned smaller models and propreitory models api calls.</p></li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://aayushgarg.dev/2024-07-03-baseline-gpt4o-structured-data/">Part I blog post of series</a></li>
<li><a href="https://huggingface.co/datasets/GEM/viggo">ViGGO Dataset</a></li>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Generate_responses_all_llms.ipynb">Notebook I: Generate_responses_all_llms.ipynb</a></li>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Compare_model_performances.ipynb">Notebook II: Compare_models_performances.ipynb</a></li>
</ul>
<hr>
<p>Thanks for reading! If you have any questions or feedback, please let me know on <a href="https://twitter.com/Aayush_ander">Twitter</a> or <a href="https://www.linkedin.com/in/aayush-garg-8b26a734/">LinkedIn</a>.</p>


</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2024-07-09-compare-models-structured-data.html</guid>
  <pubDate>Tue, 09 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Part I: Baseline Evaluation of GPT-4o for Functional Representation Extraction</title>
  <link>https://garg-aayush.github.io/posts/2024-07-03-baseline-gpt4o-structured-data.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>Extracting structured data from unstructured texts allow us to condense the information present in the text. This representation then can be used for efficient indexing and other downstream RAG applications.&nbsp;</p>
<p>I want to evaluate <a href="https://openai.com/index/hello-gpt-4o/">GPT-4o‚Äôs</a> performance in extracting structural data, specifically, functional representation, from the unstructured domain-specific text. I will use <a href="https://huggingface.co/datasets/GEM/viggo">ViGGO dataset</a> to evaluate it on custom evaluation criteria and will set it as baseline performance for that can be used for comparison in future work with other models such as <strong>Claude</strong>, <strong>Gemini</strong>, and <strong>custom</strong> fine-tuned open-source models.</p>
</section>
<section id="viggo-dataset" class="level3">
<h3 class="anchored" data-anchor-id="viggo-dataset">ViGGO Dataset</h3>
<p>This is a dataset for generating text opinions in the video game domain. Strictly speaking, it is intended to generate coherent conversational responses based on input functional representations (set of attributes and values).</p>
<p>However, I use the <strong>reverse task</strong>, where I <strong>generate structured functional representations from the given text input</strong>. A typical ViGGO dataset example has the output structured functional representation consisting of a single function with attributes and attribute values.</p>
<pre><code>Text:
You said that you liked Crysis. Do you often play first person games from Crytek Frankfurt?

Functional Representation:
verify_attribute(name[Crysis], developer[Crytek Frankfurt], rating[good], player_perspective[first person])</code></pre>
<p>The function and attributes must be one of the following, respectively:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">Function:</span>
<span id="cb2-2">[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'inform'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'request'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'give_opinion'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'confirm'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'verify_attribute'</span>, </span>
<span id="cb2-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'suggest'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'request_explanation'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'recommend'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'request_attribute'</span>]</span>
<span id="cb2-4"></span>
<span id="cb2-5">Attributes:</span>
<span id="cb2-6">[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'release_year'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'esrb'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'genres'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'platforms'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'available_on_steam'</span>,</span>
<span id="cb2-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'has_linux_release'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'has_mac_release'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'specifier'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rating'</span>, </span>
<span id="cb2-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'player_perspective'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'has_multiplayer'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'developer'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'exp_release_date'</span>]</span></code></pre></div></div>
<p><strong>Note</strong>: Since I am not training/fine-tuning any model, I will only consider the ViGGO validation datasetfor this exercise.</p>
</section>
<section id="prompt-for-generating-the-functional-representation" class="level3">
<h3 class="anchored" data-anchor-id="prompt-for-generating-the-functional-representation">Prompt for generating the functional representation</h3>
<p>I use modified version of prompt template used in <a href="https://medium.com/r?url=https%3A%2F%2Fwww.anyscale.com%2Fblog%2Ffine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications">Anyscale‚Äôs blog</a> for the ViGGO dataset. The prompt template is a few-shot prompt with examples from each function category to assist the model in understanding the intended output response representation.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">PROMPT_TEMPLATE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values. </span></span>
<span id="cb3-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come before the 'exp_release_date' attribute, and so forth.</span></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">For each attribute, fill in the corresponding value of the attribute within brackets. A couple of examples are below. Note: you are to output the string after "Output: ". Do not include "Output: " in your answer.</span></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 1)</span></span>
<span id="cb3-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.</span></span>
<span id="cb3-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: inform(name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no])</span></span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 2) </span></span>
<span id="cb3-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Were there even any terrible games in 2014?</span></span>
<span id="cb3-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: request(release_year[2014], specifier[terrible])</span></span>
<span id="cb3-16"></span>
<span id="cb3-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 3)</span></span>
<span id="cb3-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Adventure games that combine platforming and puzzles  can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.</span></span>
<span id="cb3-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: give_opinion(name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view])</span></span>
<span id="cb3-20"></span>
<span id="cb3-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 4)</span></span>
<span id="cb3-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?</span></span>
<span id="cb3-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: recommend(name[The Wolf Among Us], developer[Telltale Games])</span></span>
<span id="cb3-24"></span>
<span id="cb3-25"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 5) </span></span>
<span id="cb3-26"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Layers of Fear, the indie first person point-and-click adventure game?</span></span>
<span id="cb3-27"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: confirm(name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person])  </span></span>
<span id="cb3-28"></span>
<span id="cb3-29"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 6) </span></span>
<span id="cb3-30"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: I bet you like it when you can play games on Steam, like Worms: Reloaded, right?  </span></span>
<span id="cb3-31"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: suggest(name[Worms: Reloaded], available_on_steam[yes])</span></span>
<span id="cb3-32"></span>
<span id="cb3-33"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 7)</span></span>
<span id="cb3-34"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?    </span></span>
<span id="cb3-35"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: verify_attribute(name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo])</span></span>
<span id="cb3-36"></span>
<span id="cb3-37"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 8)</span></span>
<span id="cb3-38"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: So what is it about the games that were released in 2005 that you find so excellent?  </span></span>
<span id="cb3-39"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: request_explanation(release_year[2005], rating[excellent])</span></span>
<span id="cb3-40"></span>
<span id="cb3-41"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Example 9)</span></span>
<span id="cb3-42"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Sentence: Do you think Mac is a better gaming platform than others?</span></span>
<span id="cb3-43"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Output: request_attribute(has_mac_release[])</span></span>
<span id="cb3-44"></span>
<span id="cb3-45"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Give the output for the following sentence:</span></span>
<span id="cb3-46"><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{input}</span></span>
<span id="cb3-47"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div></div>
<p>The typical responses for the above template are not perfect but it can be used for generating structured output for the full dataset.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">Ground Truth: inform(name[FIFA <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>], release_year[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2011</span>], esrb[E (<span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> Everyone)], rating[average], genres[simulation, sport])</span>
<span id="cb4-2">GPT Response: inform(name[FIFA <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>], release_year[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2011</span>], esrb[E (<span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> Everyone)], rating[average], genres[sports, simulation])</span>
<span id="cb4-3"></span>
<span id="cb4-4"></span>
<span id="cb4-5">Ground Truth: request(player_perspective[side view], specifier[easy])</span>
<span id="cb4-6">GPT Response: Output: request(genres[side view], rating[top], specifier[easy])</span>
<span id="cb4-7"></span>
<span id="cb4-8"></span>
<span id="cb4-9">Ground Truth: recommend(name[Need <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> Speed: The Run], platforms[Xbox])</span>
<span id="cb4-10">GPT Response: confirm(name[Need <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> Speed: The Run], platforms[Xbox])</span></code></pre></div></div>
</section>
<section id="evaluation-criteria" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-criteria">Evaluation criteria</h3>
<p>Often, you require custom evaluation criteria for custom tasks. For structured functional representation extraction, I define the following binary criteria:</p>
<ol type="1">
<li><p><strong>Function Name Match</strong>: The function name must match the ground truth function name.</p></li>
<li><p><strong>Function and Attributes Match</strong>: The generated function name and attributes must match the ground truth function attributes. However, the order of the attributes does not matter.</p></li>
<li><p><strong>Function, Attributes, and Values Match</strong>: The generated function name, attributes, and values must match the ground truth function attributes and values. The order of the attributes and values does not matter.</p></li>
<li><p><strong>Exact Match</strong>: The generated function must exactly match the ground truth function.</p></li>
</ol>
<p>The above criteria are in order of increasing strictness. The first criterion is the least strict, and the last criterion is the most strict. These criteria will help me evaluate the model‚Äôs performance.</p>
</section>
<section id="evaluation-strategy" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-strategy">Evaluation Strategy</h3>
<p>Although not ideal, I ask the model to evaluate its own performance on the given task. This approach has limitations, as it could potentially introduce bias in the evaluation process. However, it serves as a starting point for our analysis. I ask the model to compare the generated function with the ground truth function and provide a boolean score based on the above evaluation criteria.</p>
<p>Since, I need the evaluation scores in a more structured format to analyze the model‚Äôs performance effectively. I use <a href="https://docs.pydantic.dev/latest/">pydantic</a> and <a href="https://python.useinstructor.com/">instructor</a> packages to obtain the evaluation scores in a structured format. I use the following prompt and pydantic model to evaluate the GPT-4o performance:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> EvaluateFunctionRepresentation(BaseModel):</span>
<span id="cb5-2">    function_match: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The function name is the same but the attributes and values can be different."</span>)</span>
<span id="cb5-3">    function_attribute_match: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The function and the attributes are the same but the values can be different."</span>)</span>
<span id="cb5-4">    function_attributes_values_match: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The generated representation has same function and attributes and corresponding values without the same attributes and values order."</span>)</span>
<span id="cb5-5">    exact_match: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The generated representation is exactly the same as the ground truth representation."</span>)</span>
<span id="cb5-6"></span>
<span id="cb5-7">PROMPT_TEMPLATE_SCORE_EVAL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""I will provide you with two functional representations strings. One will be the ground truth representation (ground_truth) and the other will be a generated representation (generated). You need to compare the generated representation with the ground truth representation and provide the following similarity match in true or false:</span></span>
<span id="cb5-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">1) function_match</span></span>
<span id="cb5-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">2) function_attributes_match</span></span>
<span id="cb5-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">3) function_attributes_values_match</span></span>
<span id="cb5-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">4) exact_match</span></span>
<span id="cb5-12"></span>
<span id="cb5-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">A typical functional representation is of this form: function(attribute1[values], attribute2[values], attribute3[values], ...). </span></span>
<span id="cb5-14"></span>
<span id="cb5-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Given the following two functional representation, provide the similarity scores for the following:</span></span>
<span id="cb5-16"></span>
<span id="cb5-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">ground_truth: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{ground_truth}</span></span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">generated: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{generated}</span></span>
<span id="cb5-20"></span>
<span id="cb5-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Let's think step by step.</span></span>
<span id="cb5-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div></div>
<p><strong>Please go through the <a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Evaluate_GPT4_Viggo_dataset.ipynb">GPT-4o baseline evaluation notebook</a> for more details on prompt template and evaluation process and responses.</strong></p>
</section>
<section id="evaluating-the-performance" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-the-performance">Evaluating the performance</h3>
<p>Using the above evaluation strategy, I generate the average evaluation scores for the full dataset.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://garg-aayush.github.io/static/img/blog-2024-07-03/gpt-4o-evaluation-metrics.png" class="img-fluid figure-img"></p>
<figcaption>GPT-4o Evaluation Metrics</figcaption>
</figure>
</div>
<p>The task of generating functional representations from natural language sentences is challenging as seen in the above scores. The best the model can do is to provide the exact match only for <strong>30%</strong> of the examples. Even the correct function name evaluation score is only about <strong>80%</strong>. These results indicate that while GPT-4o shows some capability in extracting functional representations, there‚Äôs significant room for improvement.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The above evaluation exercise provides a good baseline and useful evaluation criteria/metrics that can be used to assess the performance of other models on the same task in the future. Generating functional representations is a complex task and is not easily accomplished using prompt-engineering techniques like few-shot learning as seen in the results.</p>
</section>
<section id="next-steps" class="level3">
<h3 class="anchored" data-anchor-id="next-steps">Next steps‚Ä¶</h3>
<ul>
<li><p>Evaluate other large models like <strong>Claude</strong>, <strong>Gemini</strong>, and <strong>Llama-3‚Äì70B</strong> on the same task to compare their performance. This will provide a broader perspective on how different LLMs handle structured data extraction.</p></li>
<li><p>Explore alternative evaluation methods that don‚Äôt rely on the model evaluating itself. Most importantly, to eliminate potential biases in the evaluation process.</p></li>
<li><p>Fine-tune smaller models like <strong>Llama-3‚Äì8B</strong> or <strong>Mistral-7B</strong> for this domain-specific structured representation task. Fine-tuning will not only improve the model‚Äôs performance but also enhance latency and reduce the number of input tokens required to generate the output.</p></li>
<li><p>Investigate the impact of different prompt engineering techniques on the model‚Äôs performance.</p></li>
</ul>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://github.com/garg-aayush/llm-warehouse/blob/main/tutorials/Evaluate_GPT4_Viggo_dataset.ipynb">GPT-4o baseline evaluation notebook</a></li>
<li><a href="https://openai.com/index/hello-gpt-4o/">OpenAI GPT-4o</a></li>
<li><a href="https://huggingface.co/datasets/GEM/viggo">ViGGO Dataset</a></li>
<li><a href="https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications">Anyscale Blog on Fine-tuning Llama 2</a></li>
<li><a href="https://docs.pydantic.dev/latest/">Pydantic Documentation</a></li>
<li><a href="https://python.useinstructor.com/">Instructor Package</a></li>
</ul>
<hr>
<p>Thanks for reading! If you have any questions or feedback, please let me know on <a href="https://twitter.com/Aayush_ander">Twitter</a> or <a href="https://www.linkedin.com/in/aayush-garg-8b26a734/">LinkedIn</a>.</p>


</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2024-07-03-baseline-gpt4o-structured-data.html</guid>
  <pubDate>Wed, 03 Jul 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Step-by-Step Guide to Setup Your Personal GPU Server</title>
  <link>https://garg-aayush.github.io/posts/2024-06-30-remote-gpu-server.html</link>
  <description><![CDATA[ 




<ul>
<li><a href="https://gist.github.com/garg-aayush/d377557b20ef9f206c1d6381e174d8a7">Github Gist Link</a></li>
</ul>
<p>I‚Äôve been using a GPU workstation with an RTX 4090 for almost a year now, and it‚Äôs been one of the best decisions I‚Äôve made. With a personal GPU server, you no longer need to rely on cloud-based GPU instances from services like <code>RunPod</code> or <code>Vast.ai</code> every time you want to run a job or try new models. The best part? No stress about recurring GPU instance costs! :-)</p>
<p>However, I rarely work directly on my workstation. Instead, I prefer the flexibility of accessing the GPU remotely using my MacBook, whether I‚Äôm working from different locations within my home, from a co-working space, or a cozy cafe in another part of town.</p>
<p><strong>In this blog, I will walk you through the steps to configure a personal GPU Ubuntu server.</strong></p>
<p>For this guide, I assume you already have a workstation running Ubuntu with a GPU and it is connected to your local network</p>
<section id="setting-up-local-remote-access" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-local-remote-access">Setting Up Local Remote Access</h2>
<p>Let‚Äôs start by setting up local access, which will allow you to <code>ssh</code> into your GPU server when you‚Äôre on the same home Wi-Fi network. This is ideal for a work-from-home (WFH) setup where your workstation is running in a corner of your living space.</p>
<ol type="1">
<li><p><strong>Install the SSH server</strong></p>
<p>First, we need to install an SSH (Secure Shell) server. This will allow you to securely access your GPU machine remotely. Open a terminal on your Ubuntu machine and run the following commands: <code>bash  sudo apt update &amp;&amp;  sudo apt install openssh-server</code> This command updates your package lists and installs the OpenSSH server.</p></li>
<li><p><strong>Start and Enable SSH Service</strong></p>
<p>Next, enable the SSH service using this command: <code>bash  sudo systemctl enable --now ssh</code> You can verify if the service is enabled by running: <code>bash  sudo systemctl status ssh</code></p>
<p>Look for a line starting with <code>Active: active (running)</code> for <code>ssh.service</code>. This indicates that the SSH service is up and running.</p>
<blockquote class="blockquote">
<p>Note: The OpenSSH server starts running on boot by default.</p>
</blockquote></li>
<li><p><strong>Configure the firewall</strong></p>
<p>To allow SSH connections through the system firewall, you need to open the appropriate port. Ubuntu‚Äôs default firewall, UFW (Uncomplicated Firewall), makes this process straightforward: <code>bash  sudo ufw allow ssh</code> This command adds an exception to your firewall rules, permitting incoming SSH connections. You can check the SSH status with: <code>bash  sudo ufw status</code> You should see the output similar to: <code>bash  To                         Action      From  --                         ------      ----  22/tcp                     ALLOW       Anywhere  22/tcp(v6)                 ALLOW       Anywhere (v6)</code></p></li>
<li><p><strong>Connect to the local server</strong></p>
<p>Now that your GPU server is set up, it‚Äôs time to test the connection. From your laptop (which should be on the same local network as your GPU machine), open a terminal and use the following command: <code>bash  ssh user@local-ip-address</code> Replace user with your Ubuntu <code>user</code> and <code>local-ip-address</code> with the IP address of your GPU machine on the local network.</p>
<ul>
<li>To find your username on the workstation, you can use the <code>whoami</code> command.</li>
<li>To find your local IP address, use one of these methods on your workstation:
<ul>
<li>Run <code>hostname -I</code> and use the first address listed.</li>
<li>Use <code>ip addr show | grep -w</code> inet for more detailed network information.</li>
<li><a href="https://linuxconfig.org/how-to-find-my-ip-address-on-ubuntu-20-04-focal-fossa-linux">How to find my IP address on Ubuntu Linux</a> is a great blog on it. It explains multiple commands like <code>ip addr show | grep -w inet</code> or <code>networkctl status</code> to get the local IP address.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>Your local IP address typically starts with 192.168.</p>
<p>Note: If your router dynamically changes the local IP address of your workstation, it‚Äôs best to log into your router and assign a fixed local IP address to ensure consistent access.</p>
</blockquote>
<p>If everything is configured correctly, you‚Äôll be prompted to enter your password, after which you‚Äôll gain remote access to your GPU server.</p></li>
<li><p><strong>Set Up SSH Keys for Passwordless Login</strong></p>
<p>It is recommended to set up key-based authentication for better security and convenience purposes. This allows you to connect to your remote server without entering a password each time.</p>
<ul>
<li>It is quite common to setup ssh key-based authentication.</li>
<li>For detailed instructions on setting up SSH keys, refer to the DigitalOcean guide on <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys-on-ubuntu-20-04#step-4-disabling-password-authentication-on-your-server">Setting up SSH keys on Ubuntu 20.04</a>.</li>
</ul></li>
</ol>
</section>
<section id="setting-up-external-remote-access" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-external-remote-access">Setting Up External Remote Access</h2>
<p>While local access is great for working within your home network, sometimes you need to access your GPU workstation from outside your local network, such as from co-working spaces or a cozy cafe.</p>
<p>One simple and secure way to achieve this is by using <a href="https://ngrok.com/">ngrok</a>.</p>
<blockquote class="blockquote">
<p>ngrok helps creates secure tunnels from public endpoints to locally running services. It allows you to expose your personal server to the internet, enabling remote access from anywhere without complex network configurations.</p>
</blockquote>
<p>Here‚Äôs how to set it up:</p>
<ol type="1">
<li><p><strong>Install ngrok</strong></p>
<p>First, you need to install ngrok on your GPU workstation. Open a terminal and run this command: <code>bash  snap install ngrok</code></p>
<ul>
<li>For more installation options, see https://dashboard.ngrok.com/get-started/setup/linux.</li>
</ul></li>
<li><p><strong>Create and connect to ngrok Account</strong></p>
<p>Visit <a href="https://ngrok.com/">ngrok‚Äôs website</a> and sign up for a free account if you haven‚Äôt already. After signing up, you‚Äôll receive an auth token. On your GPU workstation, run: <code>bash  ngrok config add-authtoken YOUR_AUTH_TOKEN</code> You can get the config file path and edit using <code>ngrok config check</code> and <code>vim &lt;path&gt;</code>, respectively.</p></li>
<li><p><strong>Start the ngrok Tunnel</strong></p>
<p>Now, you can create a secure tunnel to your SSH service: <code>bash  ngrok tcp 22</code> This command will display a URL that looks like <code>tcp://X.tcp.ngrok.io:PORT</code>. Note down this URL.</p></li>
<li><p><strong>Connect to Your Workstation</strong></p>
<p>From any external laptop, you can now SSH into your GPU workstation using: <code>bash  ssh -p YYYY user@X.tcp.ngrok.io</code> Replace <code>PORT</code> with the port number and <code>X</code> with the subdomain from the ngrok URL. Replace <code>user</code> with your Ubuntu username.</p>
<p><em>The above steps ensure that you can remotely access the workstation from external network. However, no one is going to manually start the ngrok every time before heading out.</em></p></li>
<li><p><strong>Make ngrok start automatically on boot</strong></p>
<p>To ensure ngrok starts automatically when your workstation boots:</p>
<ul>
<li>Create a new service file:</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> vim /etc/systemd/system/ngrok.service</span></code></pre></div></div>
<ul>
<li>Add the following content:</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[Unit]</span></span>
<span id="cb2-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">Description</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>start <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ngrok</span> tunnel on startup</span>
<span id="cb2-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">After</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>network.target</span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[Service]</span></span>
<span id="cb2-6"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">ExecStart</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>/snap/bin/ngrok <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">tcp</span> 22</span>
<span id="cb2-7"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">Restart</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>on-failure</span>
<span id="cb2-8"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">User</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>your_username<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[Install]</span></span>
<span id="cb2-11"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">WantedBy</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>multi-user.target</span></code></pre></div></div>
<p>Replace <code>&lt;your_username&gt;</code> with your Ubuntu username. Save the file and exit the editor.</p>
<ul>
<li>Enable and start the service:</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> systemctl enable ngrok.service</span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> systemctl start ngrok.service</span></code></pre></div></div>
<p>Now ngrok will automatically start and create a tunnel when your workstation boots.</p>
<blockquote class="blockquote">
<p>Note: With a free account, ngrok assigns a new port (YYYY) each time your workstation boots. You can get the new port from the <a href="https://dashboard.ngrok.com/tunnels/agents">ngrok dashboard</a>.</p>
</blockquote></li>
<li><p><strong>Paid ngrok account for dedicated port</strong></p>
<p>For a dedicated TCP endpoint port that doesn‚Äôt change on reboot, you need a paid ngrok personal account (<code>$10/month</code>).</p>
<ol type="a">
<li>Reserve a tcp endpoint</li>
</ol>
<p>Once you have a paid account, reserve a TCP endpoint at <code>https://dashboard.ngrok.com/cloud-edge/tcp-addresses</code>.</p>
<ol start="2" type="a">
<li>Update the ngrok service file</li>
</ol>
<p>Add the following content:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[Unit]</span></span>
<span id="cb4-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">Description</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>start <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ngrok</span> tunnel on startup</span>
<span id="cb4-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">After</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>network.target</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[Service]</span></span>
<span id="cb4-6"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">ExecStart</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>/snap/bin/ngrok <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">tcp</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--region</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>region<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> --remote-addr=<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>remote-address<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> 22</span>
<span id="cb4-7"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">Restart</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>on-failure</span>
<span id="cb4-8"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">User</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&lt;</span>your_username<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[Install]</span></span>
<span id="cb4-11"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">WantedBy</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>multi-user.target</span></code></pre></div></div>
<p>Replace <code>&lt;region&gt;</code>, <code>&lt;remote-address&gt;</code>, and <code>&lt;your_username&gt;</code> with the appropriate values from your reserved TCP endpoint config.</p></li>
</ol>
<p><strong>With this setup, your SSH remote endpoint will remain the same even if the system reboots.</strong></p>
<section id="reference-links" class="level3">
<h3 class="anchored" data-anchor-id="reference-links">Reference Links:</h3>
<ol type="1">
<li><a href="https://ubuntu.com/server/docs/service-openssh">Ubuntu SSH Documentation</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys-on-ubuntu-20-04">DigitalOcean Guide on Setting Up SSH Keys</a></li>
<li><a href="https://ngrok.com/docs">ngrok Documentation</a></li>
<li><a href="https://linuxconfig.org/how-to-find-my-ip-address-on-ubuntu-20-04-focal-fossa-linux">IP Address Information for Ubuntu</a></li>
<li><a href="https://help.ubuntu.com/community/UFW">UFW (Uncomplicated Firewall) Guide</a></li>
</ol>
<hr>
<p>Thanks for reading! If you have any questions or feedback, please let me know on <a href="https://twitter.com/Aayush_ander">Twitter</a> or <a href="https://www.linkedin.com/in/aayush-garg-8b26a734/">LinkedIn</a>.</p>


</section>
</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2024-06-30-remote-gpu-server.html</guid>
  <pubDate>Sun, 30 Jun 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Managing multiple CUDA versions using environment modules in Ubuntu</title>
  <link>https://garg-aayush.github.io/posts/2024-05-19-manage-multiple-cuda.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Latest Update: May 19th, 2024</p>
</blockquote>
<ul>
<li><a href="https://gist.github.com/garg-aayush/156ec6ddda3d62e2c0ddad00b7e66956">Github Gist Link</a></li>
</ul>
<p>This blog contains all the steps required to: - Install multiple CUDA versions (e.g., <code>CUDA 11.8 and</code>CUDA 12.1 - Manage multiple CUDA environments on Ubuntu using the utility called <a href="https://modules.readthedocs.io/en/latest/">environment modules</a>. - Use this approach to avoid CUDA environment conflicts.</p>
<blockquote class="blockquote">
<p>Environment Modules is a package that provides for the dynamic modification of a user‚Äôs environment via modulefiles. You can find more on it at <a href="https://modules.readthedocs.io/en/latest/">https://modules.readthedocs.io/en/latest/</a></p>
</blockquote>
<section id="install-the-compatible-nvidia-drivers-if-required" class="level3">
<h3 class="anchored" data-anchor-id="install-the-compatible-nvidia-drivers-if-required">Install the Compatible NVIDIA Drivers (if required)</h3>
<ul>
<li><p>Add PPA GPU Drivers Repository to the System</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> add-apt-repository ppa:graphics-drivers/ppa</span></code></pre></div></div></li>
<li><p>Check GPU and available drives</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ubuntu-drivers</span> devices</span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># install it using: sudo ubuntu-drivers</span></span></code></pre></div></div></li>
<li><p>Install the compatible driver</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># best to allow Ubuntu to autodetect and install the compatible nvidia-driver</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> ubuntu-drivers install</span></code></pre></div></div>
<blockquote class="blockquote">
<p>For example, I tried to install <code>nvidia-driver-545</code> using <code>sudo ubuntu-drivers install nvidia:545</code> command. However, I was unable to install it. There was always some or the other issue.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Note</strong>: Please <strong>restart</strong> your system after installing the nvidia driver. Ideally, you should be able to get GPU state and stats using <code>nvidia-smi</code></p>
</blockquote></li>
<li><p>Check the installed NVIDIA driver</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">nvidia-detector</span> </span></code></pre></div></div></li>
<li><p>Additionally, you can also install NVIDIA drivers using the <strong>Software &amp; Updates</strong> Ubuntu app. Just go to the <strong>Additional Drivers</strong> tab, choose a driver, and click <strong>Apply Changes</strong>.</p></li>
</ul>
</section>
<section id="install-cuda-11.8-and-cuda-12.1" class="level3">
<h3 class="anchored" data-anchor-id="install-cuda-11.8-and-cuda-12.1">Install <code>CUDA 11.8</code> and <code>CUDA 12.1</code></h3>
<ul>
<li><p>Go to the <a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a> and select <code>CUDA Toolkit 11.8</code> from the available options.</p></li>
<li><p>Choose your OS, architecture, distribution, version, and installer type. For example, in my case:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Option</th>
<th style="text-align: center;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">OS</td>
<td style="text-align: center;">Linux</td>
</tr>
<tr class="even">
<td style="text-align: center;">Architecture</td>
<td style="text-align: center;">x86_64</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Distribution</td>
<td style="text-align: center;">Linux</td>
</tr>
<tr class="even">
<td style="text-align: center;">Version</td>
<td style="text-align: center;">22.04</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Installer type</td>
<td style="text-align: center;">deb(local)</td>
</tr>
</tbody>
</table></li>
<li><p>Follow the provided installation instructions by copying and pasting the commands into your terminal. This will install <code>CUDA 11.8</code>. Use the following commands:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin</span>
<span id="cb5-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600  </span>
<span id="cb5-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wget</span> https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb</span>
<span id="cb5-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> dpkg <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb</span>
<span id="cb5-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> cp /var/cuda-repo-ubuntu2204-11-8-local/cuda-<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>-keyring.gpg /usr/share/keyrings/</span>
<span id="cb5-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get update</span>
<span id="cb5-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span> install cuda</span></code></pre></div></div></li>
<li><p>Similarly, install <code>CUDA 12.1</code> using the following commands:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin</span>
<span id="cb6-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600</span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wget</span> https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb</span>
<span id="cb6-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> dpkg <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb</span>
<span id="cb6-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>-keyring.gpg /usr/share/keyrings/</span>
<span id="cb6-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get update</span>
<span id="cb6-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span> install cuda</span></code></pre></div></div></li>
<li><p>Make sure to copy and execute the commands above in your terminal to install <code>CUDA 11.8</code> and <code>CUDA 12.1</code> on your system.</p></li>
</ul>
</section>
<section id="install-cudnn-library" class="level3">
<h3 class="anchored" data-anchor-id="install-cudnn-library">Install <code>cuDNN</code> library</h3>
<ul>
<li><p>Go to <a href="https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linux-x86_64/">https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linux-x86_64/</a> and download the <code>cuDNN</code> tar for <code>CUDA 11.x</code>. Note that you might need to create a developer‚Äôs account first.</p></li>
<li><p>Untar the downloaded file using the following command:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tar</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-xvf</span> cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA 11.x</span></span>
<span id="cb7-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tar</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-xvf</span> cudnn-linux-x86_64-9.1.0.70_cuda12-archive.tar.xz <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CUDA 12.x</span></span></code></pre></div></div></li>
<li><p>Copy the <code>cuDNN</code> files to the <code>CUDA</code> toolkit files:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># for CUDA 11.8</span></span>
<span id="cb8-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> cudnn-linux-x86_64-9.1.0.70_cuda11-archive/</span>
<span id="cb8-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> cp include/cudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>.h /usr/local/cuda-11.8/include</span>
<span id="cb8-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> cp lib64/libcudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span> /usr/local/cuda-11.8/lib64</span>
<span id="cb8-5"></span>
<span id="cb8-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># for CUDA 12.1</span></span>
<span id="cb8-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> cudnn-linux-x86_64-9.1.0.70_cuda12-archive/</span>
<span id="cb8-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> cp include/cudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>.h /usr/local/cuda-12.1/include</span>
<span id="cb8-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> cp lib64/libcudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span> /usr/local/cuda-12.1/lib64</span></code></pre></div></div></li>
<li><p>Make the files executable:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> chmod a+r /usr/local/cuda-11.8/include/cudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>.h /usr/local/cuda-11.8/lib64/libcudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb9-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> chmod a+r /usr/local/cuda-12.1/include/cudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>.h /usr/local/cuda-12.1/lib64/libcudnn<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span></code></pre></div></div></li>
<li><p><strong>Note</strong>: Strictly speaking, you are done with the CUDA setup. You can use it by adding the CUDA bin and library path to the <code>PATH</code> and <code>LD_LIBRARY_PATH</code> environment variables. For example, you can set up CUDA 11.8 by adding the following lines in the <code>~/.bashrc</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">PATH</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>/usr/local/cuda-11.8/bin:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$PATH</span></span>
<span id="cb10-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">LD_LIBRARY_PATH</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>/usr/local/cuda-11.8/extras/CUPTI/lib64:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$LD_LIBRARY_PATH</span></span>
<span id="cb10-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">LD_LIBRARY_PATH</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>/usr/local/cuda-11.8/lib64:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$LD_LIBRARY_PATH</span></span></code></pre></div></div></li>
</ul>
<p>Similarly, you can set up CUDA 12.1. However, manually changing the paths every time can be cumbersome!</p>
<p><strong>Note</strong>: In case, you only want to install either of the one, CUDNN 11.x or CUDNN 12.x. The simpler way is to go to <a href="https://developer.nvidia.com/cudnn-downloads">https://developer.nvidia.com/cudnn-downloads</a> and install the CUDNN 11.x or CUDNN 12.x similar to CUDA installation.</p>
</section>
<section id="manage-multiple-cuda-versions-using-environment-modules" class="level3">
<h3 class="anchored" data-anchor-id="manage-multiple-cuda-versions-using-environment-modules">Manage multiple CUDA versions using <code>environment modules</code></h3>
<ol type="1">
<li><p><strong>Install the environment modules utility</strong></p>
<p>Run the following commands:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get update</span>
<span id="cb11-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get install environment-modules</span></code></pre></div></div>
<p>Check the installation:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check the installation by running</span></span>
<span id="cb12-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> list</span></code></pre></div></div>
<blockquote class="blockquote">
<p>You should see a list of default installed modules like git and maybe their versions displayed when you run the command <code>module list</code>. This confirms that the environment modules utility has been successfully installed on your system.</p>
</blockquote></li>
<li><p><strong>Create modulefiles for CUDA distributions</strong></p>
<blockquote class="blockquote">
<p><strong>Note</strong>: You might need root permissions to create directories and files. Use sudo in that case.</p>
</blockquote>
<p>Create a directory <code>/usr/share/modules/modulefiles/cuda</code> to hold modulefiles for cuda distributions</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> mkdir <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-p</span> /usr/share/modules/modulefiles/cuda</span></code></pre></div></div>
<p>Create a modulefile <code>/usr/share/modules/modulefiles/cuda/11.8</code> for <code>CUDA 11.8</code> and add the following lines:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#%Module1.0</span></span>
<span id="cb14-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">##</span></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## cuda 11.8 modulefile</span></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">##</span></span>
<span id="cb14-5"></span>
<span id="cb14-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">proc</span> ModulesHelp { } {</span>
<span id="cb14-7">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">global</span> version</span>
<span id="cb14-8"></span>
<span id="cb14-9">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">puts</span> stderr <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\tSets up environment for CUDA </span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$version</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">\n"</span></span>
<span id="cb14-10"><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb14-11"></span>
<span id="cb14-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module-whatis</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sets up environment for CUDA 11.8"</span></span>
<span id="cb14-13"></span>
<span id="cb14-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">{</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">[</span> is-loaded cuda/12.1 <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">]</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">}</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">{</span></span>
<span id="cb14-15"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> unload cuda/12.1</span>
<span id="cb14-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">}</span></span>
<span id="cb14-17"></span>
<span id="cb14-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> version 11.8</span>
<span id="cb14-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> root /usr/local/cuda-11.8</span>
<span id="cb14-20"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">setenv</span> CUDA_HOME    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span></span>
<span id="cb14-21"></span>
<span id="cb14-22"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">prepend-path</span> PATH <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span>/bin</span>
<span id="cb14-23"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">prepend-path</span> LD_LIBRARY_PATH <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span>/extras/CUPTI/lib64</span>
<span id="cb14-24"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">prepend-path</span> LD_LIBRARY_PATH <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span>/lib64</span>
<span id="cb14-25"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conflict</span> cuda</span></code></pre></div></div>
<p>Similarly, create a modulefile <code>/usr/share/modules/modulefiles/cuda/12.1</code> for <code>CUDA 12.1</code> and add the following lines:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#%Module1.0</span></span>
<span id="cb15-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">##</span></span>
<span id="cb15-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## cuda 12.1 modulefile</span></span>
<span id="cb15-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">##</span></span>
<span id="cb15-5"></span>
<span id="cb15-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">proc</span> ModulesHelp { } {</span>
<span id="cb15-7">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">global</span> version</span>
<span id="cb15-8"></span>
<span id="cb15-9">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">puts</span> stderr <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\tSets up environment for CUDA </span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$version</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">\n"</span></span>
<span id="cb15-10"><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb15-11"></span>
<span id="cb15-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module-whatis</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sets up environment for CUDA 12.1"</span></span>
<span id="cb15-13"></span>
<span id="cb15-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">{</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">[</span> is-loaded cuda/11.8 <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">]</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">}</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">{</span></span>
<span id="cb15-15"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> unload cuda/11.8</span>
<span id="cb15-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">}</span></span>
<span id="cb15-17"></span>
<span id="cb15-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> version 12.1</span>
<span id="cb15-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> root /usr/local/cuda-12.1</span>
<span id="cb15-20"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">setenv</span> CUDA_HOME    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span></span>
<span id="cb15-21"></span>
<span id="cb15-22"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">prepend-path</span> PATH <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span>/bin</span>
<span id="cb15-23"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">prepend-path</span> LD_LIBRARY_PATH <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span>/extras/CUPTI/lib64</span>
<span id="cb15-24"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">prepend-path</span> LD_LIBRARY_PATH <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$root</span>/lib64</span>
<span id="cb15-25"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">conflict</span> cuda</span></code></pre></div></div></li>
<li><p><strong>Make <code>CUDA 11.8</code> the default cuda version</strong></p>
<p>Create a file <code>/usr/share/modules/modulefiles/cuda.version</code> to make <code>CUDA 11.8</code> the default cuda module:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#%Module</span></span>
<span id="cb16-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> ModulesVersion 11.8</span></code></pre></div></div>
<blockquote class="blockquote">
<p><strong>Note</strong>: make sure to reload your terminal.</p>
</blockquote></li>
<li><p><strong>Changing and Viewing the CUDA Module</strong></p>
<p>To change and view the loaded CUDA module, you can use the following commands:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check the currently loaded module</span></span>
<span id="cb17-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> list</span>
<span id="cb17-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check the available modules</span></span>
<span id="cb17-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> avail</span>
<span id="cb17-5"></span>
<span id="cb17-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load a specific cuda version</span></span>
<span id="cb17-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> load cuda/12.1</span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unload the currently loaded CUDA module</span></span>
<span id="cb17-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> unload cuda</span>
<span id="cb17-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load CUDA 11.8</span></span>
<span id="cb17-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">module</span> load cuda/11.8</span>
<span id="cb17-12"></span>
<span id="cb17-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># verify the paths of the loaded CUDA</span></span>
<span id="cb17-14"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">nvcc</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--version</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># should give the loaded CUDA version</span></span>
<span id="cb17-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$CUDA_HOME</span></span>
<span id="cb17-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$PATH</span></span>
<span id="cb17-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$LD_LIBRARY_PATH</span></span></code></pre></div></div>
<blockquote class="blockquote">
<p><strong>Note</strong>: You can add additional <code>CUDA</code> versions or other packages by creating corresponding modulefiles and following the steps outlined in this gist.</p>
</blockquote></li>
</ol>
</section>
<section id="some-useful-tips" class="level3">
<h3 class="anchored" data-anchor-id="some-useful-tips">Some Useful Tips</h3>
<ol type="1">
<li><p><strong>What to do if <code>nvidia-smi</code> does not works</strong></p>
<p>Sometime, after Ubuntu update or some other weird issue. The system might not be able to detect drivers. For example, you get erros such as <code>nvidia-smi has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.</code> The best solution is to remove the current drivers and reinstall the compatible nvidia-driver.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># removes all the nvidia drivers</span></span>
<span id="cb18-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--purge</span> remove <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*nvidia*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"libxnvctrl*"</span></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># reinstall the compatible driver and restart</span></span>
<span id="cb18-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> ubuntu-drivers install</span></code></pre></div></div></li>
<li><p><strong>How to purge CUDA from your computer</strong></p>
<p><strong>&gt; DO IT AT YOUR OWN RISK</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># removes all the nvidia drivers</span></span>
<span id="cb19-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--purge</span> remove <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*nvidia*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"libxnvctrl*"</span></span>
<span id="cb19-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># remove all cuda versions</span></span>
<span id="cb19-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> apt-get <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--purge</span> remove <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*cuda*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*cublas*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*cufft*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*cufile*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*curand*"</span>  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*cusolver*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*cusparse*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*gds-tools*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*npp*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*nvjpeg*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nsight*"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*nvvm*"</span></span>
<span id="cb19-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># remove all cuda folders</span></span>
<span id="cb19-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> rm <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> /usr/loca/cuda<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span></code></pre></div></div></li>
</ol>
</section>
<section id="resources-and-helpful-links" class="level2">
<h2 class="anchored" data-anchor-id="resources-and-helpful-links">Resources and helpful links</h2>
<ul>
<li><a href="https://ubuntu.com/server/docs/nvidia-drivers-installation">https://ubuntu.com/server/docs/nvidia-drivers-installation</a></li>
<li><a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></li>
<li><a href="https://developer.nvidia.com/cudnn-downloads">https://developer.nvidia.com/cudnn-downloads</a></li>
</ul>
<hr>
<p>Thanks for reading! If you have any questions or feedback, please let me know on <a href="https://twitter.com/Aayush_ander">Twitter</a> or <a href="https://www.linkedin.com/in/aayush-garg-8b26a734/">LinkedIn</a>.</p>


</section>

 ]]></description>
  <guid>https://garg-aayush.github.io/posts/2024-05-19-manage-multiple-cuda.html</guid>
  <pubDate>Sun, 19 May 2024 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
